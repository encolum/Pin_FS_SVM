{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import parallel_backend\n",
    "import multiprocessing\n",
    "\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lõi CPU có sẵn: 20\n",
      "Model: MILP1\n",
      "\n",
      "Xử lý file: wdbc.data.txt\n",
      "Not noise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best B value: 11\n",
      "Best C value: 32\n",
      "Best Accuracy on 10-CV: 0.9735902255639097\n",
      "Best AUC on 10-CV:  0.9697416337802398\n",
      "Average time per fold: 0.11 seconds\n",
      "v: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0.]\n",
      "Features selected: [5, 11, 14, 21, 22, 23, 24, 25, 27, 28, 29]\n",
      "Number of selected features: 11\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_feature.txt\n",
      "Noise\n",
      "Best B value: 14\n",
      "Best C value: 32\n",
      "Best Accuracy on 10-CV: 0.8963345864661655\n",
      "Best AUC on 10-CV:  0.8866292392681903\n",
      "Average time per fold: 0.10 seconds\n",
      "v: [0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1.]\n",
      "Features selected: [3, 6, 9, 14, 15, 20, 21, 22, 23, 24, 25, 27, 28, 30]\n",
      "Number of selected features: 14\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_outlier.txt\n",
      "Best B value: 9\n",
      "Best C value: 32\n",
      "Best Accuracy on 10-CV: 0.9122180451127818\n",
      "Best AUC on 10-CV:  0.9241668917923601\n",
      "Average time per fold: 0.11 seconds\n",
      "v: [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 0.]\n",
      "Features selected: [2, 8, 15, 21, 22, 25, 27, 28, 29]\n",
      "Number of selected features: 9\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_both_noise_outlier.txt\n",
      "Outlier\n",
      "Best B value: 6\n",
      "Best C value: 32\n",
      "Best Accuracy on 10-CV: 0.8507205513784462\n",
      "Best AUC on 10-CV:  0.856364825445123\n",
      "Average time per fold: 0.29 seconds\n",
      "v: [0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1.]\n",
      "Features selected: [4, 5, 6, 8, 22, 30]\n",
      "Number of selected features: 6\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Kết quả đã được lưu vào file v2_model_results_wdbc.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score,roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from docplex.mp.model import Model\n",
    "import time\n",
    "import csv\n",
    "import multiprocessing\n",
    "from joblib import parallel_backend\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import multiprocessing\n",
    "from joblib import parallel_backend\n",
    "\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "print(f\"Số lõi CPU có sẵn: {n_cores}\")\n",
    "\n",
    "# Danh sách các file dữ liệu\n",
    "file_names = [\n",
    "    \"wdbc.data.txt\",\n",
    "    'wdbc_noisy_label_feature.txt',\n",
    "    'wdbc_noisy_label_outlier.txt',\n",
    "    'wdbc_both_noise_outlier.txt'\n",
    "\n",
    "]\n",
    "# Tạo danh sách để lưu kết quả\n",
    "results = []\n",
    "print('Model: MILP1')\n",
    "for iteration, file_name in enumerate(file_names):\n",
    "    \n",
    "    print(f\"\\nXử lý file: {file_name}\")\n",
    "    if iteration == 0: \n",
    "        print('Not noise')\n",
    "        noise_type = 'Not noise'\n",
    "    elif iteration == 1:\n",
    "        print('Noise')\n",
    "        noise_type = 'Noise'\n",
    "    \n",
    "    elif iteration ==2 :\n",
    "        noise_type = 'Outlier'    \n",
    "    else:\n",
    "        print('Outlier')\n",
    "        noise_type = 'Noise + Outlier'\n",
    "    \n",
    "    df = pd.read_csv(file_name, header= None)\n",
    "\n",
    "    # Tách dữ liệu và nhãn\n",
    "    X = df.iloc[:, 2:].values\n",
    "    y = df.iloc[:, 1].values\n",
    "\n",
    "    # Chuyển đổi nhãn từ B/M thành -1/1\n",
    "    y = np.where(y == 'M', 1, -1)\n",
    "\n",
    "    # Chuẩn hóa dữ liệu\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Các tham số của mô hình\n",
    "    c = [1.0] * X.shape[1]\n",
    "    l = [-2] * X.shape[1]  \n",
    "    u = [2] * X.shape[1]   \n",
    "    C_values = [2**i for i in range(-3,6)]\n",
    "\n",
    "    # Áp dụng 10-fold cross-validation để tìm giá trị tối ưu cho B\n",
    "    best_B = None\n",
    "    best_mean_cv_accuracy = 0\n",
    "    best_mean_cv_AUC = 0\n",
    "\n",
    "    # Danh sách các giá trị B cần kiểm tra\n",
    "    n = X.shape[1]\n",
    "    B_values = [i for i in range(1, n+1)]\n",
    "\n",
    "    # for C in C_values:\n",
    "    with parallel_backend('loky', n_jobs=n_cores):\n",
    "        for B in B_values:\n",
    "            for C in C_values:\n",
    "                kf = KFold(n_splits=10, shuffle=True,random_state=42)\n",
    "                cv_accuracies = []\n",
    "                cv_AUC = []\n",
    "                cv_times = []\n",
    "                \n",
    "                for train_index, val_index in kf.split(X):\n",
    "                    start_time = time.time()\n",
    "                    X_cv_train, X_cv_val = X[train_index], X[val_index]\n",
    "                    y_cv_train, y_cv_val = y[train_index], y[val_index]\n",
    "                    \n",
    "                    X_cv_train = scaler.fit_transform(X_cv_train)\n",
    "                    X_cv_val = scaler.transform(X_cv_val)\n",
    "\n",
    "                    # Khởi tạo mô hình\n",
    "                    opt_mod = Model(name='MILP1')\n",
    "\n",
    "                    # Số lượng mẫu và số lượng thuộc tính\n",
    "                    m, n = X_cv_train.shape\n",
    "\n",
    "                    # Các biến quyết định\n",
    "                    w = opt_mod.continuous_var_list(n, name='w')\n",
    "                    b = opt_mod.continuous_var(name='b')\n",
    "                    v = opt_mod.binary_var_list(n, name='v')\n",
    "                    xi = opt_mod.continuous_var_list(m, lb=0, name='xi')\n",
    "                    z = opt_mod.continuous_var_list(n,lb =0, name = 'z')\n",
    "\n",
    "                    # Hàm mục tiêu\n",
    "                    opt_mod.minimize(opt_mod.sum(xi[i] for i in range(m)))\n",
    "\n",
    "                    # Ràng buộc\n",
    "                    for i in range(m):\n",
    "                        opt_mod.add_constraint(y_cv_train[i] * (opt_mod.sum(w[j] * X_cv_train[i,j] for j in range(n)) + b) >= 1 - xi[i])\n",
    "                    for j in range(n):\n",
    "                        opt_mod.add_constraint(w[j] <= v[j] * u[j])\n",
    "                        opt_mod.add_constraint(w[j] >= l[j] * v[j])\n",
    "                        opt_mod.add_constraint(w[j] >= -z[j])\n",
    "                        opt_mod.add_constraint(w[j] <= z[j])\n",
    "                \n",
    "                    opt_mod.add_constraint(opt_mod.sum(c[j] * v[j] for j in range(n)) <= B)\n",
    "                    \n",
    "                    # Giải mô hình\n",
    "                    solution = opt_mod.solve()\n",
    "\n",
    "                    end_time = time.time()\n",
    "                    fold_time = end_time - start_time\n",
    "                    cv_times.append(fold_time)\n",
    "\n",
    "                    if solution:\n",
    "                        w_opt = np.array([solution.get_value(f'w_{j}') for j in range(n)])\n",
    "                        b_opt = solution.get_value('b')\n",
    "                        v_opt = np.array([solution.get_value(f'v_{j}') for j in range(n)])\n",
    "                        y_cv_pred = np.sign(np.dot(X_cv_val, w_opt) + b_opt)\n",
    "                        cv_accuracy = accuracy_score(y_cv_val, y_cv_pred)\n",
    "                        cv_auc = roc_auc_score(y_cv_val, y_cv_pred)\n",
    "                        cv_accuracies.append(cv_accuracy)\n",
    "                        cv_AUC.append(cv_auc)\n",
    "                    \n",
    "\n",
    "            # Đánh giá trung bình trên tập huấn luyện bằng 10-fold cross-validation với mỗi giá trị B\n",
    "            mean_cv_accuracy = np.mean(cv_accuracies)\n",
    "            mean_cv_AUC = np.mean(cv_AUC)\n",
    "            mean_time_per_fold = np.mean(cv_times)\n",
    "\n",
    "            # Cập nhật giá trị B tối ưu\n",
    "            if mean_cv_AUC > best_mean_cv_AUC:\n",
    "                best_B = B\n",
    "                best_C = C\n",
    "                best_mean_cv_accuracy = mean_cv_accuracy\n",
    "                best_mean_cv_AUC = mean_cv_AUC\n",
    "                best_mean_time_per_fold = mean_time_per_fold\n",
    "                best_w = w_opt\n",
    "                best_b = b_opt\n",
    "                best_v = v_opt\n",
    "        print(f'Best B value: {best_B}')\n",
    "        print(f'Best C value: {best_C}')\n",
    "        print(f'Best Accuracy on 10-CV: {best_mean_cv_accuracy}')\n",
    "        print(f'Best AUC on 10-CV:  {best_mean_cv_AUC}')\n",
    "        print(f'Average time per fold: {best_mean_time_per_fold:.2f} seconds')\n",
    "\n",
    "        selected_features = [j + 1 for j in range(n) if best_w[j] != 0]\n",
    "\n",
    "\n",
    "        print(f'v: {best_v}')\n",
    "        print(f'Features selected: {selected_features}')\n",
    "        print(f'Number of selected features: {len(selected_features)}')\n",
    "        print('-' * 100)\n",
    "\n",
    "        result = {\n",
    "            'Model': 'MILP1',  # Thay đổi tên mô hình tương ứng\n",
    "            'Type of model': noise_type,\n",
    "            'Accuracy': best_mean_cv_accuracy,\n",
    "            'AUC': best_mean_cv_AUC,\n",
    "            'Time': best_mean_time_per_fold,\n",
    "            'Features selected': ', '.join(map(str, selected_features)),\n",
    "            'Number of features': len(selected_features),\n",
    "            'C': best_C\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# Sau khi chạy xong tất cả các mô hình, thêm đoạn code sau để in ra file CSV\n",
    "output_file = 'model_results_wdbc.csv'\n",
    "fieldnames = ['Model', 'Type of model', 'Accuracy', 'AUC', 'Time', 'Features selected', 'Number of features', 'C']\n",
    "\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "\n",
    "print(f\"Kết quả đã được lưu vào file {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pin-FS-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lõi CPU có sẵn: 20\n",
      "Model: Pin-FS-SVM\n",
      "\n",
      "Xử lý file: wdbc.data.txt\n",
      "Not noise\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from docplex.mp.model import Model\n",
    "import time\n",
    "import multiprocessing\n",
    "from joblib import parallel_backend\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "print(f\"Số lõi CPU có sẵn: {n_cores}\")\n",
    "\n",
    "# Danh sách các file dữ liệu\n",
    "file_names = [\n",
    "    'wdbc.data.txt',\n",
    "    'wdbc_noisy_label_feature.txt',\n",
    "    'wdbc_noisy_label_outlier.txt',\n",
    "    'wdbc_both_noise_outlier.txt'\n",
    "]\n",
    "\n",
    "print('Model: Pin-FS-SVM')\n",
    "results = []\n",
    "max_time_per_file = 60 * 60  # 30 phút\n",
    "\n",
    "for iteration, file_name in enumerate(file_names):\n",
    "    print(f\"\\nXử lý file: {file_name}\")\n",
    "    if iteration == 0: \n",
    "        print('Not noise')\n",
    "        noise_type = 'Not noise'\n",
    "    elif iteration == 1:\n",
    "        print('Noise')\n",
    "        noise_type = 'Noise'\n",
    "    elif iteration == 2:\n",
    "        print('Outlier')\n",
    "        noise_type = 'Outlier'\n",
    "    else:\n",
    "        noise_type = 'Noise + Outlier'\n",
    "    \n",
    "    df = pd.read_csv(file_name, header=None)\n",
    "\n",
    "    # Tách dữ liệu và nhãn\n",
    "    X = df.iloc[:, 2:].values\n",
    "    y = df.iloc[:, 1].values\n",
    "\n",
    "    # Chuyển đổi nhãn từ B/M thành -1/1\n",
    "    y = np.where(y == 'M', 1, -1)\n",
    "\n",
    "    # Chuẩn hóa dữ liệu\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Các tham số của mô hình\n",
    "    l = [-2] * X.shape[1]\n",
    "    u = [2] * X.shape[1]\n",
    "    C_values = [2**i for i in range(-3, 6)]\n",
    "    tau_values = [0.1, 0.5, 1]\n",
    "\n",
    "    best_B = None\n",
    "    best_mean_cv_accuracy = 0\n",
    "    best_mean_cv_AUC = 0\n",
    "    no_improvement_count = 0\n",
    "\n",
    "    n = X.shape[1]\n",
    "    B_values = [i for i in range(1, n+1)]\n",
    "\n",
    "    start_file_time = time.time()\n",
    "\n",
    "    with parallel_backend('loky', n_jobs=n_cores):\n",
    "        for tau in tau_values:\n",
    "            for C in C_values:\n",
    "                for B in B_values:\n",
    "                    current_time = time.time()\n",
    "                    if current_time - start_file_time > max_time_per_file:\n",
    "                        break\n",
    "                    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "                    cv_accuracies = []\n",
    "                    cv_AUC = []\n",
    "                    cv_times = []\n",
    "\n",
    "                    for train_index, val_index in kf.split(X):\n",
    "                        start_time = time.time()\n",
    "                        X_cv_train, X_cv_val = X[train_index], X[val_index]\n",
    "                        y_cv_train, y_cv_val = y[train_index], y[val_index]\n",
    "\n",
    "                        # Chuẩn hóa dữ liệu\n",
    "                        X_cv_train = scaler.fit_transform(X_cv_train)\n",
    "                        X_cv_val = scaler.transform(X_cv_val)\n",
    "\n",
    "                        # Khởi tạo mô hình\n",
    "                        opt_mod = Model(name='Pin-FS-SVM')\n",
    "                        m, n = X_cv_train.shape\n",
    "\n",
    "                        # Các biến quyết định\n",
    "                        w = opt_mod.continuous_var_list(n, name='w')\n",
    "                        b = opt_mod.continuous_var(name='b')\n",
    "                        v = opt_mod.binary_var_list(n, name='v')\n",
    "                        xi = opt_mod.continuous_var_list(m, lb=0, name='xi')\n",
    "                        z = opt_mod.continuous_var_list(n, lb=0, name='z')\n",
    "\n",
    "                        # Hàm mục tiêu\n",
    "                        opt_mod.minimize(opt_mod.sum(z[j] for j in range(n)) + C * opt_mod.sum(xi[i] for i in range(m)))\n",
    "\n",
    "                        # Ràng buộc phân loại\n",
    "                        for i in range(m):\n",
    "                            opt_mod.add_constraint(y_cv_train[i] * (opt_mod.sum(w[j] * X_cv_train[i, j] for j in range(n)) + b) >= 1 - xi[i])\n",
    "                            opt_mod.add_constraint(y_cv_train[i] * (opt_mod.sum(w[j] * X_cv_train[i, j] for j in range(n)) + b) <= 1 + xi[i] * (1/tau))\n",
    "\n",
    "                        # Ràng buộc tổng các đặc trưng được chọn\n",
    "                        opt_mod.add_constraint(opt_mod.sum(v[j] for j in range(n)) <= B)\n",
    "\n",
    "                        for j in range(n):\n",
    "                            opt_mod.add_constraint(w[j] <= v[j] * u[j])\n",
    "                            opt_mod.add_constraint(w[j] >= l[j] * v[j])\n",
    "                            opt_mod.add_constraint(w[j] <= z[j])\n",
    "                            opt_mod.add_constraint(w[j] >= -z[j])\n",
    "\n",
    "                        # Giải mô hình\n",
    "                        solution = opt_mod.solve()\n",
    "\n",
    "                        end_time = time.time()\n",
    "                        fold_time = end_time - start_time\n",
    "                        cv_times.append(fold_time)\n",
    "\n",
    "                        if solution:\n",
    "                            w_opt = np.array([solution.get_value(f'w_{j}') for j in range(n)])\n",
    "                            b_opt = solution.get_value('b')\n",
    "                            v_opt = np.array([solution.get_value(f'v_{j}') for j in range(n)])\n",
    "                            y_cv_pred = np.sign(np.dot(X_cv_val, w_opt) + b_opt)\n",
    "                            cv_accuracy = accuracy_score(y_cv_val, y_cv_pred)\n",
    "                            cv_auc = roc_auc_score(y_cv_val, y_cv_pred)\n",
    "                            cv_accuracies.append(cv_accuracy)\n",
    "                            cv_AUC.append(cv_auc)\n",
    "                        else:\n",
    "                            print(\"Solution not found for fold.\")\n",
    "\n",
    "                    # Đánh giá trung bình trên tập huấn luyện bằng 10-fold cross-validation với mỗi giá trị B\n",
    "                    mean_cv_accuracy = np.mean(cv_accuracies)\n",
    "                    mean_cv_AUC = np.mean(cv_AUC)\n",
    "                    mean_time_per_fold = np.mean(cv_times)\n",
    "\n",
    "                    if mean_cv_AUC > best_mean_cv_AUC:\n",
    "                        best_B = B\n",
    "                        best_C = C\n",
    "                        best_tau = tau\n",
    "                        best_mean_cv_accuracy = mean_cv_accuracy\n",
    "                        best_mean_cv_AUC = mean_cv_AUC\n",
    "                        best_mean_time_per_fold = mean_time_per_fold\n",
    "                        best_w = w_opt\n",
    "                        best_b = b_opt\n",
    "                        best_v = v_opt\n",
    "                    \n",
    "    total_time = time.time() - start_file_time\n",
    "    print(f'Tổng thời gian xử lý file: {total_time/60:.2f} phút')\n",
    "    print(f'Best B value: {best_B}')\n",
    "    print(f'Best C: {best_C}')\n",
    "    print(f'Best tau: {best_tau}')\n",
    "    print(f'Best Accuracy on 10-CV: {best_mean_cv_accuracy}')\n",
    "    print(f'Best AUC on 10-CV:  {best_mean_cv_AUC}')\n",
    "    print(f'Average time per fold: {best_mean_time_per_fold:.2f} seconds')\n",
    "\n",
    "    selected_features = [j + 1 for j in range(n) if best_w[j] != 0]\n",
    "\n",
    "    print(f'v: {best_v}')\n",
    "    print(f'Features selected: {selected_features}')\n",
    "    print(f'Number of selected features: {len(selected_features)}')\n",
    "    print('-' * 100)\n",
    "    result = {\n",
    "            'Model': 'Pin-FS-SVM',  # Thay đổi tên mô hình tương ứng\n",
    "            'Type of model': noise_type,\n",
    "            'Accuracy': best_mean_cv_accuracy,\n",
    "            'AUC': best_mean_cv_AUC,\n",
    "            'Time': best_mean_time_per_fold,\n",
    "            'Features selected': ', '.join(map(str, selected_features)),\n",
    "            'Number of features': len(selected_features),\n",
    "            'C': best_C,\n",
    "            'tau': best_tau\n",
    "        }\n",
    "    results.append(result)\n",
    "\n",
    "# Sau khi chạy xong tất cả các mô hình, thêm đoạn code sau để in ra file CSV\n",
    "output_file = 'model_results_wdbc.csv'\n",
    "fieldnames = ['Model', 'Type of model', 'Accuracy', 'AUC', 'Time', 'Features selected', 'Number of features', 'C', 'tau']\n",
    "\n",
    "with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "\n",
    "print(f\"Kết quả đã được lưu vào file {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinball loss - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Pinball loss - SVM\n",
      "\n",
      "Xử lý file: wdbc.data.txt\n",
      "Not noise\n",
      "Best C:  0.125\n",
      "Best tau:  1\n",
      "Best Accuracy on 10-CV: 0.9701441102756891\n",
      "Best AUC on 10-CV:  0.9694430782592548\n",
      "Average time per fold: 0.15 seconds\n",
      "Number of selected features: 30\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_feature.txt\n",
      "Noise\n",
      "Best C:  0.125\n",
      "Best tau:  1\n",
      "Best Accuracy on 10-CV: 0.8911027568922305\n",
      "Best AUC on 10-CV:  0.8901271351506737\n",
      "Average time per fold: 0.15 seconds\n",
      "Number of selected features: 30\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_outlier.txt\n",
      "Outlier\n",
      "Best C:  0.125\n",
      "Best tau:  1\n",
      "Best Accuracy on 10-CV: 0.9209899749373432\n",
      "Best AUC on 10-CV:  0.9311907013161698\n",
      "Average time per fold: 0.15 seconds\n",
      "Number of selected features: 30\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_both_noise_outlier.txt\n",
      "Best C:  0.125\n",
      "Best tau:  1\n",
      "Best Accuracy on 10-CV: 0.8507205513784462\n",
      "Best AUC on 10-CV:  0.8574623089133178\n",
      "Average time per fold: 0.16 seconds\n",
      "Number of selected features: 30\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Kết quả đã được lưu vào file v2_model_results_wdbc.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from docplex.mp.model import Model\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import multiprocessing\n",
    "from joblib import parallel_backend\n",
    "\n",
    "# Danh sách các file dữ liệu\n",
    "file_names = [\n",
    "    \n",
    "    'wdbc.data.txt',\n",
    "    'wdbc_noisy_label_feature.txt',\n",
    "    'wdbc_noisy_label_outlier.txt',\n",
    "    'wdbc_both_noise_outlier.txt'\n",
    "\n",
    "\n",
    "]\n",
    "print('Model: Pin-SVM')\n",
    "results = []\n",
    "for iteration, file_name in enumerate(file_names):\n",
    "    \n",
    "    print(f\"\\nXử lý file: {file_name}\")\n",
    "    if iteration == 0: \n",
    "        print('Not noise')\n",
    "        noise_type = 'Not noise'\n",
    "    elif iteration == 1:\n",
    "        print('Noise')\n",
    "        noise_type = 'Noise'\n",
    "    elif iteration == 2:\n",
    "        print('Outlier')\n",
    "        noise_type = 'Outlier'\n",
    "    else:\n",
    "        noise_type = 'Noise + Outlier'\n",
    "    \n",
    "    df = pd.read_csv(file_name, header= None)\n",
    "\n",
    "    # Tách dữ liệu và nhãn\n",
    "    X = df.iloc[:, 2:].values\n",
    "    y = df.iloc[:, 1].values\n",
    "\n",
    "    # Chuyển đổi nhãn từ B/M thành -1/1\n",
    "    y = np.where(y == 'M', 1, -1)\n",
    "\n",
    "    # Chuẩn hóa dữ liệu\n",
    "    scaler = StandardScaler()\n",
    "    C_values = [2**i for i in range(-3,6)]\n",
    "    tau_values = [0.1, 0.5, 1]\n",
    "    best_mean_cv_accuracy = 0\n",
    "    best_mean_cv_AUC = 0\n",
    "    best_C = None\n",
    "    n = X.shape[1]\n",
    "    with parallel_backend('loky', n_jobs=n_cores):\n",
    "        for C in C_values:\n",
    "            for tau in tau_values:\n",
    "                kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "                cv_accuracies = []\n",
    "                cv_AUC = []\n",
    "                cv_times = []\n",
    "                \n",
    "                for train_index, val_index in kf.split(X):\n",
    "                    start_time = time.time()\n",
    "                    X_cv_train, X_cv_val = X[train_index], X[val_index]\n",
    "                    y_cv_train, y_cv_val = y[train_index], y[val_index]\n",
    "                    \n",
    "                    X_cv_train = scaler.fit_transform(X_cv_train)\n",
    "                    X_cv_val = scaler.transform(X_cv_val)\n",
    "\n",
    "                    # Khởi tạo mô hình\n",
    "                    opt_mod = Model(name='Pinball loss')\n",
    "\n",
    "                    # Số lượng mẫu và số lượng thuộc tính\n",
    "                    m, n = X_cv_train.shape\n",
    "\n",
    "                    # Các biến quyết định\n",
    "                    w = opt_mod.continuous_var_list(n, name='w')\n",
    "                    b = opt_mod.continuous_var(name='b')\n",
    "                    xi = opt_mod.continuous_var_list(m, lb=0, name='xi')\n",
    "                    \n",
    "                    \n",
    "                    # Hàm mục tiêu\n",
    "                    opt_mod.minimize(0.5 * opt_mod.sum(w[j] ** 2 for j in range(n)) + C * opt_mod.sum(xi[i] for i in range(m)))\n",
    "                    # Ràng buộc phân loại\n",
    "                    for i in range(m):\n",
    "                            opt_mod.add_constraint(y_cv_train[i] * (opt_mod.sum(w[j] * X_cv_train[i, j] for j in range(n)) + b) >= 1 - xi[i])\n",
    "                    for i in range(m):\n",
    "                            opt_mod.add_constraint(y_cv_train[i] * (opt_mod.sum(w[j] * X_cv_train[i, j] for j in range(n)) + b) <= 1 + xi[i]*(1/tau))\n",
    "\n",
    "                    \n",
    "                    # Giải mô hình\n",
    "                    solution = opt_mod.solve()\n",
    "\n",
    "                    end_time = time.time()\n",
    "                    fold_time = end_time - start_time\n",
    "                    cv_times.append(fold_time)\n",
    "\n",
    "                    if solution:\n",
    "                        w_opt = np.array([solution.get_value(f'w_{j}') for j in range(n)])\n",
    "                        b_opt = solution.get_value('b')\n",
    "                        y_cv_pred = np.sign(np.dot(X_cv_val, w_opt) + b_opt)\n",
    "                        cv_accuracy = accuracy_score(y_cv_val, y_cv_pred)\n",
    "                        cv_auc = roc_auc_score(y_cv_val, y_cv_pred)\n",
    "                        cv_accuracies.append(cv_accuracy)\n",
    "                        cv_AUC.append(cv_auc)\n",
    "                    else:\n",
    "                        print(\"Solution not found for fold.\")\n",
    "\n",
    "            mean_cv_accuracy = np.mean(cv_accuracies)\n",
    "            mean_cv_AUC = np.mean(cv_AUC)\n",
    "            mean_time_per_fold = np.mean(cv_times)\n",
    "\n",
    "            if mean_cv_accuracy > best_mean_cv_accuracy:\n",
    "                best_mean_cv_accuracy = mean_cv_accuracy\n",
    "                best_mean_cv_AUC = mean_cv_AUC\n",
    "                best_mean_time_per_fold = mean_time_per_fold\n",
    "                best_w = w_opt\n",
    "                best_C = C\n",
    "                best_b = b_opt\n",
    "                best_tau = tau\n",
    "  \n",
    "        print('Best C: ', best_C)\n",
    "        print('Best tau: ', best_tau)\n",
    "        print(f'Best Accuracy on 10-CV: {best_mean_cv_accuracy}')\n",
    "        print(f'Best AUC on 10-CV:  {best_mean_cv_AUC}')\n",
    "        print(f'Average time per fold: {best_mean_time_per_fold:.2f} seconds')\n",
    "\n",
    "        selected_features = [j + 1 for j in range(n) if best_w[j] != 0]\n",
    "\n",
    "        print(f'Number of selected features: {len(list(best_w))}')\n",
    "        print('-' * 100)\n",
    "        result = {\n",
    "            'Model': 'Pin-SVM',  # Thay đổi tên mô hình tương ứng\n",
    "            'Type of model': noise_type,\n",
    "            'Accuracy': best_mean_cv_accuracy,\n",
    "            'AUC': best_mean_cv_AUC,\n",
    "            'Time': best_mean_time_per_fold,\n",
    "            'Features selected': ', '.join(map(str, selected_features)),\n",
    "            'Number of features': len(list(best_w)),\n",
    "            'C': best_C,\n",
    "            'tau' : best_tau\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# Sau khi chạy xong tất cả các mô hình, thêm đoạn code sau để in ra file CSV\n",
    "output_file = 'model_results_wdbc.csv'\n",
    "fieldnames = ['Model', 'Type of model', 'Accuracy', 'AUC', 'Time', 'Features selected', 'Number of features', 'C', 'tau']\n",
    "\n",
    "with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "\n",
    "print(f\"Kết quả đã được lưu vào file {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 - SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: L1-SVM\n",
      "\n",
      "Xử lý file: wdbc.data.txt\n",
      "Not noise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy on 10-CV: 0.975344611528822\n",
      "Best AUC on 10-CV:  0.9729360782246843\n",
      "Average time per fold: 0.06 seconds\n",
      "Features selected: [8, 11, 14, 22, 24, 25, 27, 28, 29]\n",
      "Number of selected features: 9\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_feature.txt\n",
      "Noise\n",
      "Best Accuracy on 10-CV: 0.8963345864661655\n",
      "Best AUC on 10-CV:  0.8866292392681903\n",
      "Average time per fold: 0.06 seconds\n",
      "Features selected: [3, 6, 7, 9, 14, 15, 17, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30]\n",
      "Number of selected features: 17\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_outlier.txt\n",
      "Outlier\n",
      "Best Accuracy on 10-CV: 0.9174812030075186\n",
      "Best AUC on 10-CV:  0.9266378557877143\n",
      "Average time per fold: 0.06 seconds\n",
      "Features selected: [2, 8, 15, 21, 22, 25, 27, 28, 29]\n",
      "Number of selected features: 9\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_both_noise_outlier.txt\n",
      "Best Accuracy on 10-CV: 0.8559837092731831\n",
      "Best AUC on 10-CV:  0.8605429414831198\n",
      "Average time per fold: 0.07 seconds\n",
      "Features selected: [2, 4, 5, 6, 7, 11, 21, 22, 23, 24, 26, 28, 29, 30]\n",
      "Number of selected features: 14\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Kết quả đã được lưu vào file v2_model_results_wdbc.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from docplex.mp.model import Model\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Danh sách các file dữ liệu\n",
    "file_names = [\n",
    "    'wdbc.data.txt',\n",
    "    'wdbc_noisy_label_feature.txt',\n",
    "    'wdbc_noisy_label_outlier.txt',\n",
    "    'wdbc_both_noise_outlier.txt'\n",
    "\n",
    "]\n",
    "print('Model: L1-SVM')\n",
    "results = []\n",
    "for iteration, file_name in enumerate(file_names):\n",
    "    \n",
    "    print(f\"\\nXử lý file: {file_name}\")\n",
    "    if iteration == 0: \n",
    "        print('Not noise')\n",
    "        noise_type = 'Not noise'\n",
    "    elif iteration == 1:\n",
    "        print('Noise')\n",
    "        noise_type = 'Noise'\n",
    "    elif iteration == 2:\n",
    "        print('Outlier')\n",
    "        noise_type = 'Outlier'\n",
    "    else:\n",
    "        noise_type = 'Noise + Outlier'\n",
    "    \n",
    "    df = pd.read_csv(file_name, header= None)\n",
    "\n",
    "    # Tách dữ liệu và nhãn\n",
    "    X = df.iloc[:, 2:].values\n",
    "    y = df.iloc[:, 1].values\n",
    "\n",
    "    # Chuyển đổi nhãn từ B/M thành -1/1\n",
    "    y = np.where(y == 'M', 1, -1)\n",
    "\n",
    "    # Chuẩn hóa dữ liệu\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Các tham số của mô hình\n",
    "    C_values = [2**i for i in range(-3, 6)]\n",
    "\n",
    "    best_C = None\n",
    "    best_mean_cv_accuracy = 0\n",
    "    best_mean_cv_AUC = 0\n",
    "\n",
    "    # Áp dụng 10-fold cross-validation để tìm giá trị tối ưu cho C\n",
    "    with parallel_backend('loky', n_jobs=n_cores):\n",
    "        for C in C_values:\n",
    "            kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "            cv_accuracies = []\n",
    "            cv_AUC = []\n",
    "            cv_times = []\n",
    "\n",
    "            for train_index, val_index in kf.split(X):\n",
    "                start_time = time.time()\n",
    "\n",
    "                X_cv_train, X_cv_val = X[train_index], X[val_index]\n",
    "                y_cv_train, y_cv_val = y[train_index], y[val_index]\n",
    "                \n",
    "                X_cv_train = scaler.fit_transform(X_cv_train)\n",
    "                X_cv_val = scaler.transform(X_cv_val)\n",
    "\n",
    "                # Khởi tạo mô hình\n",
    "                opt_mod = Model(name='L1-SVM')\n",
    "\n",
    "                # Số lượng mẫu và số lượng thuộc tính\n",
    "                m, n = X_cv_train.shape\n",
    "\n",
    "                # Các biến quyết định\n",
    "                w = opt_mod.continuous_var_list(n, name='w')\n",
    "                b = opt_mod.continuous_var(name='b')\n",
    "                v = opt_mod.continuous_var_list(n, name='v', lb=0)\n",
    "                xi = opt_mod.continuous_var_list(m, lb=0, name='xi')\n",
    "\n",
    "                # Hàm mục tiêu\n",
    "                opt_mod.minimize(opt_mod.sum(v[j] for j in range(n)) + C * opt_mod.sum(xi[i] for i in range(m)))\n",
    "\n",
    "                # Ràng buộc\n",
    "                for i in range(m):\n",
    "                    opt_mod.add_constraint(y_cv_train[i] * (opt_mod.sum(w[j] * X_cv_train[i, j] for j in range(n)) + b) >= 1 - xi[i])\n",
    "                for j in range(n):\n",
    "                    opt_mod.add_constraint(w[j] <= v[j])\n",
    "                    opt_mod.add_constraint(-v[j] <= w[j])\n",
    "\n",
    "                # Giải mô hình\n",
    "                solution = opt_mod.solve()\n",
    "\n",
    "                end_time = time.time()\n",
    "                fold_time = end_time - start_time\n",
    "                cv_times.append(fold_time)\n",
    "\n",
    "                if solution:\n",
    "                    w_opt = np.array([solution.get_value(f'w_{j}') for j in range(n)])\n",
    "                    b_opt = solution.get_value('b')\n",
    "                    y_cv_pred = np.sign(np.dot(X_cv_val, w_opt) + b_opt)\n",
    "                    cv_accuracy = accuracy_score(y_cv_val, y_cv_pred)\n",
    "                    cv_auc = roc_auc_score(y_cv_val, y_cv_pred)\n",
    "                    cv_accuracies.append(cv_accuracy)\n",
    "                    cv_AUC.append(cv_auc)\n",
    "\n",
    "            # Đánh giá trung bình trên tập huấn luyện bằng 10-fold cross-validation với mỗi giá trị C\n",
    "            mean_cv_accuracy = np.mean(cv_accuracies)\n",
    "            mean_cv_AUC = np.mean(cv_AUC)\n",
    "            mean_time_per_fold = np.mean(cv_times)\n",
    "\n",
    "            # Cập nhật giá trị C tối ưu\n",
    "            if mean_cv_accuracy > best_mean_cv_accuracy:\n",
    "                best_C = C\n",
    "                best_mean_cv_accuracy = mean_cv_accuracy\n",
    "                best_mean_cv_AUC = mean_cv_AUC\n",
    "                best_mean_time_per_fold = mean_time_per_fold\n",
    "                best_w = w_opt\n",
    "                best_b = b_opt\n",
    "       \n",
    "        print(f'Best Accuracy on 10-CV: {best_mean_cv_accuracy}')\n",
    "        print(f'Best AUC on 10-CV:  {best_mean_cv_AUC}')\n",
    "        print(f'Average time per fold: {best_mean_time_per_fold:.2f} seconds')\n",
    "\n",
    "        selected_features = [j + 1 for j in range(n) if best_w[j] != 0]\n",
    "\n",
    "\n",
    "        \n",
    "        print(f'Features selected: {selected_features}')\n",
    "        print(f'Number of selected features: {len(selected_features)}')\n",
    "        print('-' * 100)\n",
    "        result = {\n",
    "            'Model': 'L1-SVM',  # Thay đổi tên mô hình tương ứng\n",
    "            'Type of model': noise_type,\n",
    "            'Accuracy': best_mean_cv_accuracy,\n",
    "            'AUC': best_mean_cv_AUC,\n",
    "            'Time': best_mean_time_per_fold,\n",
    "            'Features selected': ', '.join(map(str, selected_features)),\n",
    "            'Number of features': len(selected_features),\n",
    "            'C': best_C\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# # Sau khi chạy xong tất cả các mô hình, thêm đoạn code sau để in ra file CSV\n",
    "output_file = 'model_results_wdbc.csv'\n",
    "fieldnames = ['Model', 'Type of model', 'Accuracy', 'AUC', 'Time', 'Features selected', 'Number of features', 'C']\n",
    "\n",
    "with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "\n",
    "print(f\"Kết quả đã được lưu vào file {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: L2-SVM\n",
      "\n",
      "Xử lý file: wdbc.data.txt\n",
      "Not noise\n",
      "Best Accuracy on 10-CV: 0.9770989974937343\n",
      "Best AUC on 10-CV:  0.9742874295760358\n",
      "Average time per fold: 0.09 seconds\n",
      "Features selected: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "Number of selected features: 30\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_feature.txt\n",
      "Noise\n",
      "Best Accuracy on 10-CV: 0.8981203007518797\n",
      "Best AUC on 10-CV:  0.8891292392681903\n",
      "Average time per fold: 0.09 seconds\n",
      "Features selected: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "Number of selected features: 30\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_outlier.txt\n",
      "Outlier\n",
      "Best Accuracy on 10-CV: 0.9122180451127818\n",
      "Best AUC on 10-CV:  0.9222224473479155\n",
      "Average time per fold: 0.09 seconds\n",
      "Features selected: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "Number of selected features: 30\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Xử lý file: wdbc_both_noise_outlier.txt\n",
      "Best Accuracy on 10-CV: 0.8524749373433584\n",
      "Best AUC on 10-CV:  0.8562451741565139\n",
      "Average time per fold: 0.09 seconds\n",
      "Features selected: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "Number of selected features: 30\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Kết quả đã được lưu vào file v2_model_results_wdbc.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from docplex.mp.model import Model\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Danh sách các file dữ liệu\n",
    "file_names = [\n",
    "    'wdbc.data.txt',\n",
    "    'wdbc_noisy_label_feature.txt',\n",
    "    'wdbc_noisy_label_outlier.txt',\n",
    "    'wdbc_both_noise_outlier.txt'\n",
    "   \n",
    "]\n",
    "print('Model: L2-SVM')\n",
    "results = []\n",
    "for iteration, file_name in enumerate(file_names):\n",
    "    \n",
    "    print(f\"\\nXử lý file: {file_name}\")\n",
    "    if iteration == 0: \n",
    "        print('Not noise')\n",
    "        noise_type = 'Not noise'\n",
    "    elif iteration == 1:\n",
    "        print('Noise')\n",
    "        noise_type = 'Noise'\n",
    "    elif iteration == 2:\n",
    "        print('Outlier')\n",
    "        noise_type = 'Outlier'\n",
    "    else:\n",
    "        noise_type = 'Noise + Outlier'\n",
    "    \n",
    "    df = pd.read_csv(file_name, header= None)\n",
    "\n",
    "    # Tách dữ liệu và nhãn\n",
    "    X = df.iloc[:, 2:].values\n",
    "    y = df.iloc[:, 1].values\n",
    "\n",
    "    # Chuyển đổi nhãn từ B/M thành -1/1\n",
    "    y = np.where(y == 'M', 1, -1)\n",
    "\n",
    "    # Chuẩn hóa dữ liệu\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    \n",
    "\n",
    "    best_mean_cv_accuracy = 0\n",
    "    best_mean_cv_AUC = 0\n",
    "    best_C = None\n",
    "    C_values = [2**i for i in range(-3, 6)]\n",
    "\n",
    "    with parallel_backend('loky', n_jobs=n_cores):\n",
    "        for C in C_values:\n",
    "            kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "            cv_accuracies = []\n",
    "            cv_AUC = []\n",
    "            cv_times = []\n",
    "\n",
    "            for train_index, val_index in kf.split(X):\n",
    "                start_time = time.time()\n",
    "\n",
    "                X_cv_train, X_cv_val = X[train_index], X[val_index]\n",
    "                y_cv_train, y_cv_val = y[train_index], y[val_index]\n",
    "                \n",
    "                X_cv_train = scaler.fit_transform(X_cv_train)\n",
    "                X_cv_val = scaler.transform(X_cv_val)\n",
    "\n",
    "                # Khởi tạo mô hình\n",
    "                opt_mod = Model(name='L2-SVM')\n",
    "\n",
    "                # Số lượng mẫu và số lượng thuộc tính\n",
    "                m, n = X_cv_train.shape\n",
    "\n",
    "                # Các biến quyết định\n",
    "                w = opt_mod.continuous_var_list(n, name='w')\n",
    "                b = opt_mod.continuous_var(name='b')\n",
    "                xi = opt_mod.continuous_var_list(m, lb=0, name='xi')\n",
    "\n",
    "                # Hàm mục tiêu\n",
    "                opt_mod.minimize(0.5 * opt_mod.sum(w[j] ** 2 for j in range(n)) + C * opt_mod.sum(xi[i] for i in range(m)))\n",
    "\n",
    "                # Ràng buộc\n",
    "                for i in range(m):\n",
    "                    opt_mod.add_constraint(y_cv_train[i] * (opt_mod.sum(w[j] * X_cv_train[i, j] for j in range(n)) + b) >= 1 - xi[i])\n",
    "                \n",
    "                # Giải mô hình\n",
    "                solution = opt_mod.solve()\n",
    "\n",
    "                end_time = time.time()\n",
    "                fold_time = end_time - start_time\n",
    "                cv_times.append(fold_time)\n",
    "\n",
    "                if solution:\n",
    "                    w_opt = np.array([solution.get_value(f'w_{j}') for j in range(n)])\n",
    "                    b_opt = solution.get_value('b')\n",
    "                    y_cv_pred = np.sign(np.dot(X_cv_val, w_opt) + b_opt)\n",
    "                    cv_accuracy = accuracy_score(y_cv_val, y_cv_pred)\n",
    "                    cv_auc = roc_auc_score(y_cv_val, y_cv_pred)\n",
    "                    cv_accuracies.append(cv_accuracy)\n",
    "                    cv_AUC.append(cv_auc)\n",
    "                    \n",
    "\n",
    "            mean_cv_accuracy = np.mean(cv_accuracies)\n",
    "            mean_cv_AUC = np.mean(cv_AUC)\n",
    "            mean_time_per_fold = np.mean(cv_times)\n",
    "\n",
    "            if mean_cv_accuracy > best_mean_cv_accuracy:\n",
    "                best_C = C\n",
    "                best_mean_cv_accuracy = mean_cv_accuracy\n",
    "                best_mean_cv_AUC = mean_cv_AUC\n",
    "                best_mean_time_per_fold = mean_time_per_fold\n",
    "                best_w = w_opt\n",
    "                best_b = b_opt\n",
    "        print(f'Best Accuracy on 10-CV: {best_mean_cv_accuracy}')\n",
    "        print(f'Best AUC on 10-CV:  {best_mean_cv_AUC}')\n",
    "        print(f'Average time per fold: {best_mean_time_per_fold:.2f} seconds')\n",
    "\n",
    "        selected_features = [j + 1 for j in range(n) if best_w[j] != 0]\n",
    "\n",
    "\n",
    "        print(f'Features selected: {selected_features}')\n",
    "        print(f'Number of selected features: {len(selected_features)}')\n",
    "        print('-' * 100)\n",
    "        result = {\n",
    "            'Model': 'L2-SVM',  # Thay đổi tên mô hình tương ứng\n",
    "            'Type of model': noise_type,\n",
    "            'Accuracy': best_mean_cv_accuracy,\n",
    "            'AUC': best_mean_cv_AUC,\n",
    "            'Time': best_mean_time_per_fold,\n",
    "            'Features selected': ', '.join(map(str, selected_features)),\n",
    "            'Number of features': len(selected_features),\n",
    "            'C': best_C\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# Sau khi chạy xong tất cả các mô hình, thêm đoạn code sau để in ra file CSV\n",
    "output_file = 'model_results_wdbc.csv'\n",
    "fieldnames = ['Model', 'Type of model', 'Accuracy', 'AUC', 'Time', 'Features selected', 'Number of features', 'C']\n",
    "\n",
    "with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "\n",
    "print(f\"Kết quả đã được lưu vào file {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Filter2 - SVM\n",
      "\n",
      "Xử lý file: wdbc.data.txt\n",
      "Not noise\n",
      "Accuracy tốt nhất: 0.975344611528822\n",
      "Các đặc trưng tốt nhất: [ 1  3  7  8 21 23 24 28]\n",
      "So luong featuers 8\n",
      "AUC tốt nhất: 0.9729360782246843\n",
      "C tốt nhất: 2\n",
      "Threshold tốt nhất: 0.929985405467777\n",
      "Average time per fold: 0.046454326311747236\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_feature.txt\n",
      "Noise\n",
      "Accuracy tốt nhất: 0.8980889724310778\n",
      "Các đặc trưng tốt nhất: [ 1  2  3  4  6  7  8  9 10 11 13 14 20 21 22 23 24 26 27 28 29 30]\n",
      "So luong featuers 22\n",
      "AUC tốt nhất: 0.8885523161912673\n",
      "C tốt nhất: 4\n",
      "Threshold tốt nhất: 0.002937872127186127\n",
      "Average time per fold: 0.05363657474517822\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_outlier.txt\n",
      "Outlier\n",
      "Accuracy tốt nhất: 0.9122180451127818\n",
      "Các đặc trưng tốt nhất: [ 1  3  4  6  7  8 21 22 23 24 25 26 27 28 29]\n",
      "So luong featuers 15\n",
      "AUC tốt nhất: 0.9249024705767195\n",
      "C tốt nhất: 0.25\n",
      "Threshold tốt nhất: 0.20504563485399674\n",
      "Average time per fold: 0.04773511356777615\n",
      "\n",
      "Xử lý file: wdbc_both_noise_outlier.txt\n",
      "Accuracy tốt nhất: 0.850689223057644\n",
      "Các đặc trưng tốt nhất: [ 1  3  4 21 22 23 24 27]\n",
      "So luong featuers 8\n",
      "AUC tốt nhất: 0.8570880531977625\n",
      "C tốt nhất: 1\n",
      "Threshold tốt nhất: 0.11305818057485277\n",
      "Average time per fold: 0.046690469317966034\n",
      "Kết quả đã được lưu vào file v2_model_results_wdbc.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from docplex.mp.model import Model\n",
    "import time\n",
    "\n",
    "# Danh sách các file dữ liệu\n",
    "file_names = [\n",
    "    \"wdbc.data.txt\",\n",
    "    'wdbc_noisy_label_feature.txt',\n",
    "    'wdbc_noisy_label_outlier.txt',\n",
    "    'wdbc_both_noise_outlier.txt'\n",
    "]\n",
    "\n",
    "# Tạo danh sách để lưu kết quả\n",
    "results = []\n",
    "print('Model: Fisher - SVM')\n",
    "def calculate_f_score(X, y):\n",
    "    pos_indices = y == 1\n",
    "    neg_indices = y == -1\n",
    "    \n",
    "    X_positive = X[pos_indices]\n",
    "    X_negative = X[neg_indices]\n",
    "    \n",
    "    # So luong mau duong am\n",
    "    n_positive = X_positive.shape[0]\n",
    "    n_negative = X_negative.shape[0]\n",
    "    \n",
    "    pos_mean = np.mean(X_positive, axis=0)\n",
    "    neg_mean = np.mean(X_negative, axis=0)\n",
    "    total_mean = np.mean(X, axis=0)\n",
    "    \n",
    "    variance_positive = np.sum((X_positive - pos_mean)**2, axis=0) / (n_positive - 1)\n",
    "    variance_negative = np.sum((X_negative - neg_mean)**2, axis=0) / (n_negative - 1)\n",
    "    \n",
    "    numerator = (pos_mean - total_mean)**2 + (neg_mean - total_mean)**2\n",
    "    denominator = variance_positive + variance_negative\n",
    "    \n",
    "    f_scores = numerator / denominator\n",
    "    return f_scores\n",
    "\n",
    "def svm_train_qp(X, y, C, lambda_val=1e-5):\n",
    "        # Khởi tạo mô hình\n",
    "        opt_mod = Model(name='L1-SVM')\n",
    "\n",
    "        # Số lượng mẫu và số lượng thuộc tính\n",
    "        m, n = X.shape\n",
    "\n",
    "        # Các biến quyết định\n",
    "        w = opt_mod.continuous_var_list(n, name='w')\n",
    "        b = opt_mod.continuous_var(name='b')\n",
    "        v = opt_mod.continuous_var_list(n, name='v', lb=0)\n",
    "        xi = opt_mod.continuous_var_list(m, lb=0, name='xi')\n",
    "\n",
    "        # Hàm mục tiêu\n",
    "        opt_mod.minimize(opt_mod.sum(v[j] for j in range(n)) + C * opt_mod.sum(xi[i] for i in range(m)))\n",
    "\n",
    "        # Ràng buộc\n",
    "        for i in range(m):\n",
    "            opt_mod.add_constraint(y[i] * (opt_mod.sum(w[j] * X[i, j] for j in range(n)) + b) >= 1 - xi[i])\n",
    "        for j in range(n):\n",
    "            opt_mod.add_constraint(w[j] <= v[j])\n",
    "            opt_mod.add_constraint(-v[j] <= w[j])\n",
    "        \n",
    "        solution = opt_mod.solve()\n",
    "        if solution:\n",
    "            w_opt = np.array([solution.get_value(w[j]) for j in range(n)])\n",
    "            b_opt = solution.get_value(b)\n",
    "            return w_opt, b_opt\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def feature_selection_with_f_score_cv(X, y, thresholds, C_values):\n",
    "    f_scores = calculate_f_score(X, y)\n",
    "    best_accuracy = 0 \n",
    "    best_auc = 0\n",
    "    best_threshold = None\n",
    "    best_error = float('inf')\n",
    "    avg_fold_times = []\n",
    "    for C in C_values:\n",
    "        for threshold in thresholds:\n",
    "            selected_features = f_scores >= threshold\n",
    "            X_selected = X[:, selected_features]\n",
    "            \n",
    "            errors = []\n",
    "            for _ in range(5):\n",
    "                X_train, X_valid, y_train, y_valid = train_test_split(X_selected, y, test_size=0.2)\n",
    "                \n",
    "                scaler = StandardScaler()\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_valid_scaled = scaler.transform(X_valid)\n",
    "                \n",
    "                w, b = svm_train_qp(X_train_scaled, y_train, C=C)\n",
    "                \n",
    "                if w is None:\n",
    "                    continue\n",
    "                \n",
    "                y_pred = np.sign(np.dot(X_valid_scaled, w) + b)\n",
    "                error = 1 - accuracy_score(y_valid, y_pred)\n",
    "                errors.append(error)\n",
    "            \n",
    "            avg_error = np.mean(errors)\n",
    "            if avg_error < best_error:\n",
    "                best_error = avg_error\n",
    "                best_threshold = threshold\n",
    "                \n",
    "        selected_features = f_scores >= best_threshold\n",
    "        X_subset = X[:, selected_features]\n",
    "        \n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        cv_accuracies = []\n",
    "        cv_aucs = []\n",
    "        times = []\n",
    "            \n",
    "        for train_idx, val_idx in kf.split(X_subset):\n",
    "            # Dữ liệu huấn luyện và kiểm tra\n",
    "            start_time = time.time()\n",
    "            X_train, X_val = X_subset[train_idx], X_subset[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            # Chuẩn hóa trên tập huấn luyện và áp dụng vào tập kiểm tra\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_val = scaler.transform(X_val)\n",
    "\n",
    "            # Tính b_opt dựa trên tập huấn luyện\n",
    "            w_opt, b_opt = svm_train_qp(X_train, y_train, C=C)\n",
    "            if w_opt is None:\n",
    "                continue\n",
    "            y_pred = np.sign(np.dot(X_val, w_opt) + b_opt)\n",
    "            cv_accuracies.append(accuracy_score(y_val, y_pred))\n",
    "            cv_aucs.append(roc_auc_score(y_val, y_pred))\n",
    "            end_time = time.time()\n",
    "            times.append(end_time - start_time)\n",
    "        \n",
    "        mean_accuracy = np.mean(cv_accuracies)\n",
    "        mean_auc = np.mean(cv_aucs)\n",
    "        mean_time = np.mean(times)\n",
    "        avg_fold_times.append(mean_time)\n",
    "        \n",
    "        \n",
    "        if mean_auc > best_auc:\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_auc = mean_auc\n",
    "            best_threshold = threshold\n",
    "            best_C = C\n",
    "        \n",
    "    # Lưu lại accuracy và số lượng đặc trưng nếu tốt hơn kết quả tốt nhất\n",
    "    avg_time_per_fold = np.mean(avg_fold_times)\n",
    "    return selected_features, best_accuracy, best_auc, best_C, best_threshold, avg_time_per_fold\n",
    "\n",
    "# Kết quả\n",
    "C_values = [2**i for i in range(-3, 6)]\n",
    "\n",
    "for iteration, file_name in enumerate(file_names):\n",
    "    print(f\"\\nXử lý file: {file_name}\")\n",
    "    if iteration == 0: \n",
    "        print('Not noise')\n",
    "        noise_type = 'Not noise'\n",
    "    elif iteration == 1:\n",
    "        print('Noise')\n",
    "        noise_type = 'Noise'\n",
    "    elif iteration == 2:\n",
    "        print('Outlier')\n",
    "        noise_type = 'Outlier'\n",
    "    else:\n",
    "        noise_type = 'Noise + Outlier'\n",
    "    \n",
    "    # Đọc file\n",
    "    df = pd.read_csv(file_name, header=None)\n",
    "    X = df.iloc[:, 2:].values\n",
    "    y = np.where(df.iloc[:, 1].values == 'M', 1, -1)\n",
    "    \n",
    "    thresholds = np.percentile(calculate_f_score(X, y), [25, 50, 75])\n",
    "    selected_features, best_accuracy, best_auc, best_C, best_threshold, avg_time_per_fold = feature_selection_with_f_score_cv(X, y, thresholds, C_values)\n",
    "    \n",
    "    print(\"Accuracy tốt nhất:\", best_accuracy)\n",
    "    print(\"Các đặc trưng tốt nhất:\", np.where(selected_features)[0] + 1)\n",
    "    print('So luong featuers', len(np.where(selected_features)[0]))\n",
    "    print('AUC tốt nhất:', best_auc)\n",
    "    print('C tốt nhất:', best_C)\n",
    "    print('Threshold tốt nhất:', best_threshold)\n",
    "    print('Average time per fold:', avg_time_per_fold)\n",
    "    result ={\n",
    "        'Model': 'Fisher - SVM',\n",
    "        'Type of model': noise_type,\n",
    "        'Accuracy': best_accuracy,\n",
    "        'AUC': best_auc,\n",
    "        'Time': avg_time_per_fold,\n",
    "        'Features selected': ', '.join(map(str, np.where(selected_features)[0] + 1)),\n",
    "        'Number of features': len(np.where(selected_features)[0]),\n",
    "        'C': best_C\n",
    "        \n",
    "    }\n",
    "    results.append(result)\n",
    "output_file = 'model_results_wdbc.csv'\n",
    "fieldnames = ['Model', 'Type of model', 'Accuracy', 'AUC', 'Time', 'Features selected', 'Number of features', 'C']\n",
    "\n",
    "with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "\n",
    "print(f\"Kết quả đã được lưu vào file {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lõi CPU có sẵn: 20\n",
      "Model: RFE2-SVM\n",
      "\n",
      "Xử lý file: wdbc.data.txt\n",
      "Not noise\n",
      "Số lượng đặc trưng tốt nhất: 8\n",
      "Accuracy tốt nhất: 0.9806077694235589\n",
      "Các đặc trưng tốt nhất: [11, 14, 22, 24, 25, 27, 28, 29]\n",
      "AUC tốt nhất: 0.977150332801842\n",
      "Giá trị C tốt nhất: 1\n",
      "Thời gian trung bình mỗi fold: 0.04185357093811035\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_feature.txt\n",
      "Noise\n",
      "Số lượng đặc trưng tốt nhất: 15\n",
      "Accuracy tốt nhất: 0.89984335839599\n",
      "Các đặc trưng tốt nhất: [3, 6, 9, 14, 15, 17, 20, 21, 22, 23, 24, 25, 27, 28, 30]\n",
      "AUC tốt nhất: 0.8910661422345051\n",
      "Giá trị C tốt nhất: 2\n",
      "Thời gian trung bình mỗi fold: 0.047022652626037595\n",
      "\n",
      "Xử lý file: wdbc_noisy_label_outlier.txt\n",
      "Outlier\n",
      "Số lượng đặc trưng tốt nhất: 30\n",
      "Accuracy tốt nhất: 0.9174812030075186\n",
      "Các đặc trưng tốt nhất: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "AUC tốt nhất: 0.9266378557877143\n",
      "Giá trị C tốt nhất: 0.25\n",
      "Thời gian trung bình mỗi fold: 0.07300240993499756\n",
      "\n",
      "Xử lý file: wdbc_both_noise_outlier.txt\n",
      "Số lượng đặc trưng tốt nhất: 8\n",
      "Accuracy tốt nhất: 0.8594924812030076\n",
      "Các đặc trưng tốt nhất: [4, 6, 7, 21, 22, 23, 26, 28]\n",
      "AUC tốt nhất: 0.8652070145504194\n",
      "Giá trị C tốt nhất: 0.125\n",
      "Thời gian trung bình mỗi fold: 0.04441218376159668\n",
      "Kết quả đã được lưu vào file v2_model_results_wdbc.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from docplex.mp.model import Model\n",
    "import multiprocessing\n",
    "import time\n",
    "import csv\n",
    "\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "print(f\"Số lõi CPU có sẵn: {n_cores}\")\n",
    "\n",
    "# Danh sách các file dữ liệu\n",
    "file_names = [\n",
    "    \"wdbc.data.txt\",\n",
    "    'wdbc_noisy_label_feature.txt',\n",
    "    'wdbc_noisy_label_outlier.txt',\n",
    "    'wdbc_both_noise_outlier.txt'\n",
    "]\n",
    "\n",
    "# Tạo danh sách để lưu kết quả\n",
    "results = []\n",
    "print('Model: RFE-SVM')\n",
    "\n",
    "for iteration, file_name in enumerate(file_names):\n",
    "    print(f\"\\nXử lý file: {file_name}\")\n",
    "    if iteration == 0: \n",
    "        print('Not noise')\n",
    "        noise_type = 'Not noise'\n",
    "    elif iteration == 1:\n",
    "        print('Noise')\n",
    "        noise_type = 'Noise'\n",
    "    elif iteration == 2:\n",
    "        print('Outlier')\n",
    "        noise_type = 'Outlier'\n",
    "    else:\n",
    "        noise_type = 'Noise + Outlier'\n",
    "    \n",
    "    # Đọc file\n",
    "    df = pd.read_csv(file_name, header=None)\n",
    "    X = df.iloc[:, 2:].values\n",
    "    y = np.where(df.iloc[:, 1].values == 'M', 1, -1)\n",
    "\n",
    "    # SVM huấn luyện sử dụng Quadratic Programming (QP)\n",
    "    def svm_train_qp(X, y, C, lambda_val=1e-5):\n",
    "        # Khởi tạo mô hình\n",
    "        opt_mod = Model(name='L1-SVM')\n",
    "\n",
    "        # Số lượng mẫu và số lượng thuộc tính\n",
    "        m, n = X.shape\n",
    "\n",
    "        # Các biến quyết định\n",
    "        w = opt_mod.continuous_var_list(n, name='w')\n",
    "        b = opt_mod.continuous_var(name='b')\n",
    "        v = opt_mod.continuous_var_list(n, name='v', lb=0)\n",
    "        xi = opt_mod.continuous_var_list(m, lb=0, name='xi')\n",
    "\n",
    "        # Hàm mục tiêu\n",
    "        opt_mod.minimize(opt_mod.sum(v[j] for j in range(n)) + C * opt_mod.sum(xi[i] for i in range(m)))\n",
    "\n",
    "        # Ràng buộc\n",
    "        for i in range(m):\n",
    "            opt_mod.add_constraint(y[i] * (opt_mod.sum(w[j] * X[i, j] for j in range(n)) + b) >= 1 - xi[i])\n",
    "        for j in range(n):\n",
    "            opt_mod.add_constraint(w[j] <= v[j])\n",
    "            opt_mod.add_constraint(-v[j] <= w[j])\n",
    "        \n",
    "        solution = opt_mod.solve()\n",
    "        if solution:\n",
    "            w_opt = np.array([solution.get_value(w[j]) for j in range(n)])\n",
    "            b_opt = solution.get_value(b)\n",
    "            return w_opt, b_opt\n",
    "        return None, None\n",
    "\n",
    "    # Hàm SVM-RFE với tìm kiếm Cross-Validation và tối ưu C\n",
    "    def svm_rfe_with_cv(X, y, C_values):\n",
    "        s = list(range(X.shape[1]))  # Các đặc trưng ban đầu\n",
    "        best_result = {'accuracy': 0, 'auc': 0, 'num_features': len(s), 'features': s[:], 'C': None, 'avg_time_per_fold': 0}\n",
    "        \n",
    "        for C in C_values:\n",
    "            s_temp = s[:]  # Bắt đầu với tất cả các đặc trưng ban đầu trong mỗi vòng lặp của C\n",
    "            while len(s_temp) > 1:\n",
    "                # Lấy các đặc trưng hiện tại trong s_temp\n",
    "                X_subset = X[:, s_temp]\n",
    "                w_opt, b_opt = svm_train_qp(X_subset, y, C)\n",
    "                if w_opt is None:\n",
    "                    break\n",
    "\n",
    "                # Đánh giá mô hình bằng Cross-Validation\n",
    "                cv_accuracies, cv_aucs = [], []\n",
    "                times = []\n",
    "                kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "                for train_idx, val_idx in kf.split(X_subset):\n",
    "                    start_time = time.time()\n",
    "                    X_train, X_val = X_subset[train_idx], X_subset[val_idx]\n",
    "                    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "                    # Chuẩn hóa\n",
    "                    scaler = StandardScaler()\n",
    "                    X_train = scaler.fit_transform(X_train)\n",
    "                    X_val = scaler.transform(X_val)\n",
    "\n",
    "                    w_opt, b_opt = svm_train_qp(X_train, y_train, C)\n",
    "                    if w_opt is None:\n",
    "                        continue\n",
    "\n",
    "                    y_pred = np.sign(np.dot(X_val, w_opt) + b_opt)\n",
    "                    cv_accuracies.append(accuracy_score(y_val, y_pred))\n",
    "                    cv_aucs.append(roc_auc_score(y_val, y_pred))\n",
    "                    end_time = time.time()\n",
    "                    times.append(end_time - start_time)\n",
    "\n",
    "                mean_accuracy = np.mean(cv_accuracies)\n",
    "                mean_auc = np.mean(cv_aucs)\n",
    "                mean_time_per_fold = np.mean(times)\n",
    "\n",
    "                # Cập nhật kết quả tốt nhất cho giá trị C hiện tại\n",
    "                if mean_auc > best_result['auc']:\n",
    "                    best_result.update({\n",
    "                        'accuracy': mean_accuracy,\n",
    "                        'auc': mean_auc,\n",
    "                        'num_features': len(s_temp),\n",
    "                        'features': s_temp[:],\n",
    "                        'C': C,\n",
    "                        'avg_time_per_fold': mean_time_per_fold\n",
    "                    })\n",
    "\n",
    "                # Loại bỏ đặc trưng ít quan trọng nhất\n",
    "                num_to_remove = len(s_temp) // 2 \n",
    "                least_important_features = np.argsort(w_opt ** 2)[:num_to_remove]\n",
    "                s_temp = [s_temp[i] for i in range (len(s_temp)) if i not in least_important_features]\n",
    "\n",
    "        return best_result\n",
    "\n",
    "    # Danh sách các giá trị C để tìm kiếm\n",
    "    C_values = [2 ** i for i in range(-3, 6)]\n",
    "    \n",
    "    # Gọi hàm SVM-RFE với tìm kiếm giá trị C tối ưu\n",
    "    best_result = svm_rfe_with_cv(X, y, C_values)\n",
    "\n",
    "    # In kết quả\n",
    "    print(\"Số lượng đặc trưng tốt nhất:\", best_result['num_features'])\n",
    "    print(\"Accuracy tốt nhất:\", best_result['accuracy'])\n",
    "    print(\"Các đặc trưng tốt nhất:\", list( i + 1 for i in best_result['features'] ))\n",
    "    print(\"AUC tốt nhất:\", best_result['auc'])\n",
    "    print(\"Giá trị C tốt nhất:\", best_result['C'])\n",
    "    print(\"Thời gian trung bình mỗi fold:\", best_result['avg_time_per_fold'])\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'RFE-SVM',\n",
    "        'Type of model': noise_type,\n",
    "        'Accuracy': best_result['accuracy'],\n",
    "        'AUC': best_result['auc'],\n",
    "        'Time': best_result['avg_time_per_fold'],\n",
    "        'Features selected': ', '.join(map(str, list( i + 1 for i in best_result['features'] ))),\n",
    "        'Number of features': best_result['num_features'],\n",
    "        'C': best_result['C']\n",
    "    })\n",
    "\n",
    "output_file = 'model_results_wdbc.csv'\n",
    "fieldnames = ['Model', 'Type of model', 'Accuracy', 'AUC', 'Time', 'Features selected', 'Number of features', 'C']\n",
    "\n",
    "with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "print(f\"Kết quả đã được lưu vào file {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
