{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a9cc042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Dataset: diabetes\n",
      "Dataset Types: 4 - ['outlier', 'original', 'noise', 'both']\n",
      "Models to compare: ['PinFSSVM', 'FisherSVM']\n",
      "Expected samples per model: 4 * 10 folds = 40\n",
      "\n",
      "--- Bắt đầu merge cho dataset: diabetes ---\n",
      "\n",
      "Processing model: PinFSSVM\n",
      "  Loading: diabetes/outlier/PinFSSVM_auc_folds.xlsx\n",
      "  Loading: diabetes/original/PinFSSVM_auc_folds.xlsx\n",
      "  Loading: diabetes/noise/PinFSSVM_auc_folds.xlsx\n",
      "  Loading: diabetes/both/PinFSSVM_auc_folds.xlsx\n",
      "  Total samples for PinFSSVM: 40\n",
      "\n",
      "Processing model: FisherSVM\n",
      "  Loading: diabetes/outlier/FisherSVM_auc_folds.xlsx\n",
      "  Loading: diabetes/original/FisherSVM_auc_folds.xlsx\n",
      "  Loading: diabetes/noise/FisherSVM_auc_folds.xlsx\n",
      "  Loading: diabetes/both/FisherSVM_auc_folds.xlsx\n",
      "  Total samples for FisherSVM: 40\n",
      "\n",
      "--- Kết quả merge cho dataset diabetes ---\n",
      "Total DataFrame shape: (80, 8)\n",
      "Total missing files: 0\n",
      "\n",
      "--- Thống kê dữ liệu merged ---\n",
      "Columns: ['Model', 'Dataset', 'Dataset_Type', 'Fold', 'AUC', 'Best_C', 'Best_tau', 'Best_B']\n",
      "Total rows: 80\n",
      "\n",
      "Samples per model:\n",
      "  FisherSVM: 40 samples\n",
      "  PinFSSVM: 40 samples\n",
      "\n",
      "Samples per dataset type:\n",
      "  both: 20 samples\n",
      "  noise: 20 samples\n",
      "  original: 20 samples\n",
      "  outlier: 20 samples\n",
      "\n",
      "First 10 rows:\n",
      "      Model   Dataset Dataset_Type  Fold       AUC  Best_C  Best_tau  Best_B\n",
      "0  PinFSSVM  diabetes      outlier     1  0.755636     0.5       0.1     4.0\n",
      "1  PinFSSVM  diabetes      outlier     2  0.737179     0.5       0.1     4.0\n",
      "2  PinFSSVM  diabetes      outlier     3  0.649561     0.5       0.1     4.0\n",
      "3  PinFSSVM  diabetes      outlier     4  0.775769     0.5       0.1     4.0\n",
      "4  PinFSSVM  diabetes      outlier     5  0.834275     0.5       0.1     4.0\n",
      "5  PinFSSVM  diabetes      outlier     6  0.663121     0.5       0.1     4.0\n",
      "6  PinFSSVM  diabetes      outlier     7  0.716312     0.5       0.1     4.0\n",
      "7  PinFSSVM  diabetes      outlier     8  0.675385     0.5       0.1     4.0\n",
      "8  PinFSSVM  diabetes      outlier     9  0.710438     0.5       0.1     4.0\n",
      "9  PinFSSVM  diabetes      outlier    10  0.755844     0.5       0.1     4.0\n",
      "\n",
      "Missing values per column:\n",
      "Model            0\n",
      "Dataset          0\n",
      "Dataset_Type     0\n",
      "Fold             0\n",
      "AUC              0\n",
      "Best_C           0\n",
      "Best_tau        40\n",
      "Best_B          40\n",
      "dtype: int64\n",
      "✅ Đã lưu dữ liệu merged vào: D:\\Optimal-Robust-Feature-Selection-For-Support-Vector-Machines-With-Pinball-Loss\\src\\experiment\\results\\wilcoxon\\merged_diabetes_data.xlsx\n",
      "   Shape: (80, 8)\n",
      "✅ Đã lưu dữ liệu merged vào: D:\\Optimal-Robust-Feature-Selection-For-Support-Vector-Machines-With-Pinball-Loss\\src\\experiment\\results\\wilcoxon\\merged_diabetes_data.csv\n",
      "--- So sánh PinFSSVM vs FisherSVM trên dataset diabetes ---\n",
      "PinFSSVM samples: 40\n",
      "FisherSVM samples: 40\n",
      "\n",
      "Paired samples for comparison: 40\n",
      "\n",
      "Comparison Statistics:\n",
      "PinFSSVM AUC - Mean: 0.7240, Std: 0.0571\n",
      "FisherSVM AUC - Mean: 0.7089, Std: 0.0599\n",
      "Difference (PinFSSVM - FisherSVM) - Mean: 0.0151, Std: 0.0243\n",
      "\n",
      "--- Phân bố paired data theo Dataset_Type ---\n",
      "Dataset_Type\n",
      "both        10\n",
      "noise       10\n",
      "original    10\n",
      "outlier     10\n",
      "Name: count, dtype: int64\n",
      "✅ Đã lưu dữ liệu so sánh vào: D:\\Optimal-Robust-Feature-Selection-For-Support-Vector-Machines-With-Pinball-Loss\\src\\experiment\\results\\wilcoxon\\comparison_PinFSSVM_vs_FisherSVM_diabetes.xlsx\n",
      "\n",
      "First 10 pairs:\n",
      "  Dataset_Type  Fold  AUC_PinFSSVM  AUC_FisherSVM  Difference\n",
      "0      outlier     1      0.755636       0.755636    0.000000\n",
      "1      outlier     2      0.737179       0.717949    0.019231\n",
      "2      outlier     3      0.649561       0.598246    0.051316\n",
      "3      outlier     4      0.775769       0.776538   -0.000769\n",
      "4      outlier     5      0.834275       0.761770    0.072505\n",
      "5      outlier     6      0.663121       0.679787   -0.016667\n",
      "6      outlier     7      0.716312       0.695035    0.021277\n",
      "7      outlier     8      0.675385       0.675385    0.000000\n",
      "8      outlier     9      0.710438       0.614478    0.095960\n",
      "9      outlier    10      0.755844       0.779654   -0.023810\n",
      "\n",
      "--- Chuẩn bị cho Wilcoxon Test ---\n",
      "Dataset: diabetes\n",
      "Total paired samples: 40\n",
      "Expected samples: 40 = 4 types × 10 folds\n",
      "✅ Perfect! Có đúng số cặp dữ liệu mong đợi.\n",
      "\n",
      "=== WILCOXON SIGNED-RANK TEST cho dataset diabetes ===\n",
      "So sánh: PinFSSVM vs FisherSVM\n",
      "Số cặp dữ liệu: 40\n",
      "\n",
      "Kết quả test:\n",
      "Test statistic: 86.0\n",
      "P-value (two-sided): 0.000299\n",
      "✅ Có sự khác biệt có ý nghĩa thống kê (p < 0.05)\n",
      "   PinFSSVM có performance tốt hơn FisherSVM\n",
      "\n",
      "P-value (PinFSSVM > FisherSVM): 0.000150\n",
      "✅ PinFSSVM tốt hơn FisherSVM một cách có ý nghĩa thống kê\n",
      "=== TÓM TẮT KẾT QUẢ CHO DATASET diabetes ===\n",
      "\n",
      "Thống kê tổng quan:\n",
      "Dataset: diabetes\n",
      "Models compared: ['PinFSSVM', 'FisherSVM']\n",
      "Total records: 80\n",
      "Dataset types: 4 - ['outlier', 'original', 'noise', 'both']\n",
      "\n",
      "Thống kê AUC cho từng model:\n",
      "           count    mean     std     min     max\n",
      "Model                                           \n",
      "FisherSVM     40  0.7089  0.0599  0.5882  0.8444\n",
      "PinFSSVM      40  0.7240  0.0571  0.5969  0.8344\n",
      "\n",
      "Thống kê AUC theo Dataset_Type:\n",
      "                          mean     std\n",
      "Model     Dataset_Type                \n",
      "FisherSVM both          0.6683  0.0501\n",
      "          noise         0.7293  0.0570\n",
      "          original      0.7326  0.0517\n",
      "          outlier       0.7054  0.0648\n",
      "PinFSSVM  both          0.6834  0.0500\n",
      "          noise         0.7382  0.0601\n",
      "          original      0.7469  0.0463\n",
      "          outlier       0.7274  0.0565\n",
      "\n",
      "✅ Hoàn thành phân tích cho dataset diabetes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Đường dẫn gốc đến thư mục chứa dữ liệu wilcoxon\n",
    "BASE_DIR = r\"D:\\Optimal-Robust-Feature-Selection-For-Support-Vector-Machines-With-Pinball-Loss\\src\\experiment\\results\\wilcoxon\"\n",
    "\n",
    "# Danh sách các thành phần\n",
    "ALL_DATASETS = ['wdbc', 'sonar', 'ionosphere', 'diabetes', 'cleveland']\n",
    "DATASET_TYPES = ['outlier', 'original', 'noise', 'both'] \n",
    "ALL_MODELS = ['RFESVM', 'PinFSSVM', 'PinballSVM', 'MILP1', 'L2SVM', 'L1SVM', 'FisherSVM']\n",
    "\n",
    "# CẤU HÌNH: Chọn dataset và models cần so sánh\n",
    "TARGET_DATASET = 'diabetes'  # Thay đổi dataset ở đây\n",
    "MODELS_TO_COMPARE = ['PinFSSVM', 'FisherSVM']  # Chọn 2 models để so sánh\n",
    "\n",
    "print(f\"Target Dataset: {TARGET_DATASET}\")\n",
    "print(f\"Dataset Types: {len(DATASET_TYPES)} - {DATASET_TYPES}\")\n",
    "print(f\"Models to compare: {MODELS_TO_COMPARE}\")\n",
    "print(f\"Expected samples per model: {len(DATASET_TYPES)} * 10 folds = {len(DATASET_TYPES) * 10}\")\n",
    "\n",
    "def load_excel_file(file_path):\n",
    "    \"\"\"Load dữ liệu từ file Excel và trả về DataFrame\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_excel(file_path)\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"  Warning: File not found: {file_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"  Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def merge_single_dataset(dataset_name, models_list):\n",
    "    \"\"\"Merge dữ liệu cho 1 dataset cụ thể và danh sách models\"\"\"\n",
    "    \n",
    "    all_data = []\n",
    "    missing_files = []\n",
    "    \n",
    "    print(f\"\\n--- Bắt đầu merge cho dataset: {dataset_name} ---\")\n",
    "    \n",
    "    for model in models_list:\n",
    "        print(f\"\\nProcessing model: {model}\")\n",
    "        model_data = []\n",
    "        \n",
    "        for dataset_type in DATASET_TYPES:\n",
    "            # Tạo đường dẫn đến file\n",
    "            file_path = os.path.join(BASE_DIR, dataset_name, dataset_type, f\"{model}_auc_folds.xlsx\")\n",
    "            \n",
    "            print(f\"  Loading: {dataset_name}/{dataset_type}/{model}_auc_folds.xlsx\")\n",
    "            \n",
    "            # Load dữ liệu\n",
    "            df = load_excel_file(file_path)\n",
    "            \n",
    "            if df is not None:\n",
    "                # Thêm thông tin metadata vào DataFrame\n",
    "                df['Model'] = model\n",
    "                df['Dataset'] = dataset_name\n",
    "                df['Dataset_Type'] = dataset_type\n",
    "                \n",
    "                # Thêm vào danh sách\n",
    "                model_data.append(df)\n",
    "                all_data.append(df)\n",
    "            else:\n",
    "                missing_files.append(file_path)\n",
    "        \n",
    "        # Tính số samples cho model này\n",
    "        total_samples_for_model = sum([len(df) for df in model_data])\n",
    "        print(f\"  Total samples for {model}: {total_samples_for_model}\")\n",
    "    \n",
    "    # Merge tất cả dữ liệu\n",
    "    if all_data:\n",
    "        merged_df = pd.concat(all_data, ignore_index=True)\n",
    "        print(f\"\\n--- Kết quả merge cho dataset {dataset_name} ---\")\n",
    "        print(f\"Total DataFrame shape: {merged_df.shape}\")\n",
    "        print(f\"Total missing files: {len(missing_files)}\")\n",
    "        \n",
    "        return merged_df, missing_files\n",
    "    else:\n",
    "        print(\"No data to merge!\")\n",
    "        return None, missing_files\n",
    "\n",
    "# Thực hiện merge cho dataset được chọn\n",
    "merged_data, missing_files = merge_single_dataset(TARGET_DATASET, MODELS_TO_COMPARE)\n",
    "\n",
    "if merged_data is not None:\n",
    "    print(\"\\n--- Thống kê dữ liệu merged ---\")\n",
    "    print(f\"Columns: {list(merged_data.columns)}\")\n",
    "    print(f\"Total rows: {len(merged_data)}\")\n",
    "    \n",
    "    # Kiểm tra số lượng samples cho mỗi model\n",
    "    print(\"\\nSamples per model:\")\n",
    "    model_counts = merged_data['Model'].value_counts().sort_index()\n",
    "    for model, count in model_counts.items():\n",
    "        print(f\"  {model}: {count} samples\")\n",
    "    \n",
    "    # Kiểm tra số lượng samples cho mỗi dataset type\n",
    "    print(\"\\nSamples per dataset type:\")\n",
    "    type_counts = merged_data['Dataset_Type'].value_counts().sort_index()\n",
    "    for dtype, count in type_counts.items():\n",
    "        print(f\"  {dtype}: {count} samples\")\n",
    "    \n",
    "    # Hiển thị một vài dòng đầu\n",
    "    print(\"\\nFirst 10 rows:\")\n",
    "    print(merged_data.head(10))\n",
    "    \n",
    "    # Hiển thị thông tin về missing values\n",
    "    print(f\"\\nMissing values per column:\")\n",
    "    print(merged_data.isnull().sum())\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\n--- Missing files ({len(missing_files)}) ---\")\n",
    "    for file in missing_files:\n",
    "        print(f\"  {file}\")\n",
    "\n",
    "# Lưu dữ liệu merged vào file Excel\n",
    "if 'merged_data' in locals() and merged_data is not None:\n",
    "    \n",
    "    # Tạo tên file output với tên dataset\n",
    "    output_file = os.path.join(BASE_DIR, f\"merged_{TARGET_DATASET}_data.xlsx\")\n",
    "    \n",
    "    try:\n",
    "        # Lưu vào Excel\n",
    "        merged_data.to_excel(output_file, index=False)\n",
    "        print(f\"✅ Đã lưu dữ liệu merged vào: {output_file}\")\n",
    "        print(f\"   Shape: {merged_data.shape}\")\n",
    "        \n",
    "        # Tạo thêm một file CSV\n",
    "        csv_output_file = os.path.join(BASE_DIR, f\"merged_{TARGET_DATASET}_data.csv\")\n",
    "        merged_data.to_csv(csv_output_file, index=False)\n",
    "        print(f\"✅ Đã lưu dữ liệu merged vào: {csv_output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Lỗi khi lưu file: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Không có dữ liệu để lưu\")\n",
    "\n",
    "# So sánh 2 models cho dataset được chọn\n",
    "if 'merged_data' in locals() and merged_data is not None and len(MODELS_TO_COMPARE) == 2:\n",
    "    \n",
    "    model1 = MODELS_TO_COMPARE[0]  # PinFSSVM\n",
    "    model2 = MODELS_TO_COMPARE[1]  # RFESVM\n",
    "    \n",
    "    # Lấy dữ liệu cho 2 models\n",
    "    model1_data = merged_data[merged_data['Model'] == model1].copy()\n",
    "    model2_data = merged_data[merged_data['Model'] == model2].copy()\n",
    "    \n",
    "    print(f\"--- So sánh {model1} vs {model2} trên dataset {TARGET_DATASET} ---\")\n",
    "    print(f\"{model1} samples: {len(model1_data)}\")\n",
    "    print(f\"{model2} samples: {len(model2_data)}\")\n",
    "    \n",
    "    # Tạo cặp dữ liệu để so sánh (cùng dataset_type, fold)\n",
    "    comparison_df = pd.merge(\n",
    "        model1_data[['Dataset_Type', 'Fold', 'AUC']],\n",
    "        model2_data[['Dataset_Type', 'Fold', 'AUC']],\n",
    "        on=['Dataset_Type', 'Fold'],\n",
    "        suffixes=(f'_{model1}', f'_{model2}')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nPaired samples for comparison: {len(comparison_df)}\")\n",
    "    \n",
    "    if len(comparison_df) > 0:\n",
    "        # Hiển thị thống kê\n",
    "        auc1_col = f'AUC_{model1}'\n",
    "        auc2_col = f'AUC_{model2}'\n",
    "        \n",
    "        print(f\"\\nComparison Statistics:\")\n",
    "        print(f\"{model1} AUC - Mean: {comparison_df[auc1_col].mean():.4f}, Std: {comparison_df[auc1_col].std():.4f}\")\n",
    "        print(f\"{model2} AUC - Mean: {comparison_df[auc2_col].mean():.4f}, Std: {comparison_df[auc2_col].std():.4f}\")\n",
    "        \n",
    "        # Tính differences\n",
    "        comparison_df['Difference'] = comparison_df[auc1_col] - comparison_df[auc2_col]\n",
    "        print(f\"Difference ({model1} - {model2}) - Mean: {comparison_df['Difference'].mean():.4f}, Std: {comparison_df['Difference'].std():.4f}\")\n",
    "        \n",
    "        # Hiển thị phân bố theo dataset_type\n",
    "        print(f\"\\n--- Phân bố paired data theo Dataset_Type ---\")\n",
    "        distribution = comparison_df['Dataset_Type'].value_counts().sort_index()\n",
    "        print(distribution)\n",
    "        \n",
    "        # Lưu dữ liệu so sánh\n",
    "        comparison_output = os.path.join(BASE_DIR, f\"comparison_{model1}_vs_{model2}_{TARGET_DATASET}.xlsx\")\n",
    "        comparison_df.to_excel(comparison_output, index=False)\n",
    "        print(f\"✅ Đã lưu dữ liệu so sánh vào: {comparison_output}\")\n",
    "        \n",
    "        # Hiển thị một vài dòng đầu\n",
    "        print(f\"\\nFirst 10 pairs:\")\n",
    "        print(comparison_df.head(10)[['Dataset_Type', 'Fold', auc1_col, auc2_col, 'Difference']])\n",
    "        \n",
    "        # Chuẩn bị cho Wilcoxon test\n",
    "        model1_scores = comparison_df[auc1_col].values\n",
    "        model2_scores = comparison_df[auc2_col].values\n",
    "        \n",
    "        print(f\"\\n--- Chuẩn bị cho Wilcoxon Test ---\")\n",
    "        print(f\"Dataset: {TARGET_DATASET}\")\n",
    "        print(f\"Total paired samples: {len(model1_scores)}\")\n",
    "        print(f\"Expected samples: {len(DATASET_TYPES) * 10} = {len(DATASET_TYPES)} types × 10 folds\")\n",
    "        \n",
    "        if len(model1_scores) == len(DATASET_TYPES) * 10:\n",
    "            print(\"✅ Perfect! Có đúng số cặp dữ liệu mong đợi.\")\n",
    "        else:\n",
    "            print(f\"⚠️ Thiếu {len(DATASET_TYPES) * 10 - len(model1_scores)} cặp dữ liệu.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"❌ Không tìm thấy cặp dữ liệu phù hợp để so sánh\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cần có đúng 2 models để so sánh hoặc không có dữ liệu merged\")\n",
    "\n",
    "# Thực hiện Wilcoxon test cho 1 dataset\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "if 'model1_scores' in locals() and 'model2_scores' in locals():\n",
    "    \n",
    "    print(f\"\\n=== WILCOXON SIGNED-RANK TEST cho dataset {TARGET_DATASET} ===\")\n",
    "    print(f\"So sánh: {MODELS_TO_COMPARE[0]} vs {MODELS_TO_COMPARE[1]}\")\n",
    "    print(f\"Số cặp dữ liệu: {len(model1_scores)}\")\n",
    "    \n",
    "    # Test 2-sided (kiểm tra có khác biệt hay không)\n",
    "    statistic, p_value = wilcoxon(model1_scores, model2_scores, alternative='two-sided')\n",
    "    \n",
    "    print(f\"\\nKết quả test:\")\n",
    "    print(f\"Test statistic: {statistic}\")\n",
    "    print(f\"P-value (two-sided): {p_value:.6f}\")\n",
    "    \n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(f\"✅ Có sự khác biệt có ý nghĩa thống kê (p < {alpha})\")\n",
    "        \n",
    "        # Kiểm tra model nào tốt hơn\n",
    "        if np.mean(model1_scores) > np.mean(model2_scores):\n",
    "            print(f\"   {MODELS_TO_COMPARE[0]} có performance tốt hơn {MODELS_TO_COMPARE[1]}\")\n",
    "        else:\n",
    "            print(f\"   {MODELS_TO_COMPARE[1]} có performance tốt hơn {MODELS_TO_COMPARE[0]}\")\n",
    "    else:\n",
    "        print(f\"❌ Không có sự khác biệt có ý nghĩa thống kê (p >= {alpha})\")\n",
    "    \n",
    "    # Test 1-sided để kiểm tra model1 có tốt hơn model2 không\n",
    "    statistic_greater, p_value_greater = wilcoxon(model1_scores, model2_scores, alternative='greater')\n",
    "    print(f\"\\nP-value ({MODELS_TO_COMPARE[0]} > {MODELS_TO_COMPARE[1]}): {p_value_greater:.6f}\")\n",
    "    \n",
    "    if p_value_greater < alpha:\n",
    "        print(f\"✅ {MODELS_TO_COMPARE[0]} tốt hơn {MODELS_TO_COMPARE[1]} một cách có ý nghĩa thống kê\")\n",
    "    else:\n",
    "        print(f\"❌ Không thể khẳng định {MODELS_TO_COMPARE[0]} tốt hơn {MODELS_TO_COMPARE[1]}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Không có dữ liệu để thực hiện Wilcoxon test\")\n",
    "\n",
    "# Tóm tắt kết quả cho dataset\n",
    "if 'merged_data' in locals() and merged_data is not None:\n",
    "    \n",
    "    print(f\"=== TÓM TẮT KẾT QUẢ CHO DATASET {TARGET_DATASET} ===\")\n",
    "    \n",
    "    # Thống kê tổng quan\n",
    "    print(f\"\\nThống kê tổng quan:\")\n",
    "    print(f\"Dataset: {TARGET_DATASET}\")\n",
    "    print(f\"Models compared: {MODELS_TO_COMPARE}\")\n",
    "    print(f\"Total records: {len(merged_data)}\")\n",
    "    print(f\"Dataset types: {len(DATASET_TYPES)} - {DATASET_TYPES}\")\n",
    "    \n",
    "    # Thống kê AUC cho từng model\n",
    "    if 'AUC' in merged_data.columns:\n",
    "        print(f\"\\nThống kê AUC cho từng model:\")\n",
    "        auc_stats = merged_data.groupby('Model')['AUC'].agg(['count', 'mean', 'std', 'min', 'max']).round(4)\n",
    "        print(auc_stats)\n",
    "        \n",
    "        # Thống kê AUC theo Dataset_Type\n",
    "        print(f\"\\nThống kê AUC theo Dataset_Type:\")\n",
    "        auc_by_type = merged_data.groupby(['Model', 'Dataset_Type'])['AUC'].agg(['mean', 'std']).round(4)\n",
    "        print(auc_by_type)\n",
    "    \n",
    "    print(f\"\\n✅ Hoàn thành phân tích cho dataset {TARGET_DATASET}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Không có dữ liệu để tóm tắt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bc3868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WILCOXON SIGNED-RANK TEST FOR diabetes ===\n",
      "Comparing: PinFSSVM vs FisherSVM\n",
      "\n",
      "--- Dataset: diabetes ---\n",
      "PinFSSVM samples: 40\n",
      "FisherSVM samples: 40\n",
      "Paired samples: 40\n",
      "Mean PinFSSVM: 0.7240\n",
      "Mean FisherSVM: 0.7089\n",
      "Mean difference: 0.0151\n",
      "Statistic: 86.0\n",
      "P-value (two-sided): 0.000299\n",
      "P-value (PinFSSVM > FisherSVM): 0.000150\n",
      "✅ PinFSSVM significantly better than FisherSVM\n",
      "\n",
      "=== WILCOXON TEST SUMMARY ===\n",
      "    Dataset  Mean1   Mean2  Mean_Diff  P_value_two  Significant  Model1_Better\n",
      "0  diabetes  0.724  0.7089     0.0151       0.0003         True           True\n",
      "\n",
      "✅ Wilcoxon results saved to: D:\\Optimal-Robust-Feature-Selection-For-Support-Vector-Machines-With-Pinball-Loss\\src\\experiment\\results\\wilcoxon\\wilcoxon_results_PinFSSVM_vs_FisherSVM_diabetes.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Import thư viện cần thiết\n",
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# OPTION 1: Wilcoxon test cho dataset hiện tại (TARGET_DATASET)\n",
    "if 'merged_data' in locals() and merged_data is not None:\n",
    "    \n",
    "    print(f\"=== WILCOXON SIGNED-RANK TEST FOR {TARGET_DATASET} ===\")\n",
    "    print(f\"Comparing: {MODELS_TO_COMPARE[0]} vs {MODELS_TO_COMPARE[1]}\")\n",
    "    \n",
    "    # Lấy dữ liệu cho 2 models\n",
    "    model1_data = merged_data[merged_data['Model'] == MODELS_TO_COMPARE[0]]\n",
    "    model2_data = merged_data[merged_data['Model'] == MODELS_TO_COMPARE[1]]\n",
    "    \n",
    "    print(f\"\\n--- Dataset: {TARGET_DATASET} ---\")\n",
    "    print(f\"{MODELS_TO_COMPARE[0]} samples: {len(model1_data)}\")\n",
    "    print(f\"{MODELS_TO_COMPARE[1]} samples: {len(model2_data)}\")\n",
    "    \n",
    "    # Create paired comparison\n",
    "    paired_comparison = pd.merge(\n",
    "        model1_data[['Dataset_Type', 'Fold', 'AUC']],\n",
    "        model2_data[['Dataset_Type', 'Fold', 'AUC']],\n",
    "        on=['Dataset_Type', 'Fold'],\n",
    "        suffixes=(f'_{MODELS_TO_COMPARE[0]}', f'_{MODELS_TO_COMPARE[1]}')\n",
    "    )\n",
    "    \n",
    "    if len(paired_comparison) > 0:\n",
    "        # Extract AUC scores\n",
    "        scores1 = paired_comparison[f'AUC_{MODELS_TO_COMPARE[0]}'].values\n",
    "        scores2 = paired_comparison[f'AUC_{MODELS_TO_COMPARE[1]}'].values\n",
    "        \n",
    "        print(f\"Paired samples: {len(scores1)}\")\n",
    "        print(f\"Mean {MODELS_TO_COMPARE[0]}: {scores1.mean():.4f}\")\n",
    "        print(f\"Mean {MODELS_TO_COMPARE[1]}: {scores2.mean():.4f}\")\n",
    "        print(f\"Mean difference: {(scores1 - scores2).mean():.4f}\")\n",
    "        \n",
    "        # Perform Wilcoxon test\n",
    "        try:\n",
    "            # Two-sided test\n",
    "            statistic, p_value_two = wilcoxon(scores1, scores2, alternative='two-sided')\n",
    "            \n",
    "            # One-sided test (model1 > model2)\n",
    "            _, p_value_greater = wilcoxon(scores1, scores2, alternative='greater')\n",
    "            \n",
    "            # Determine significance\n",
    "            alpha = 0.05\n",
    "            significant = p_value_two < alpha\n",
    "            model1_better = p_value_greater < alpha\n",
    "            \n",
    "            # Store results\n",
    "            result = {\n",
    "                'Dataset': TARGET_DATASET,\n",
    "                'Model1': MODELS_TO_COMPARE[0],\n",
    "                'Model2': MODELS_TO_COMPARE[1],\n",
    "                'Pairs': len(scores1),\n",
    "                'Mean1': scores1.mean(),\n",
    "                'Mean2': scores2.mean(),\n",
    "                'Mean_Diff': (scores1 - scores2).mean(),\n",
    "                'Statistic': statistic,\n",
    "                'P_value_two': p_value_two,\n",
    "                'P_value_greater': p_value_greater,\n",
    "                'Significant': significant,\n",
    "                'Model1_Better': model1_better\n",
    "            }\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"Statistic: {statistic}\")\n",
    "            print(f\"P-value (two-sided): {p_value_two:.6f}\")\n",
    "            print(f\"P-value ({MODELS_TO_COMPARE[0]} > {MODELS_TO_COMPARE[1]}): {p_value_greater:.6f}\")\n",
    "            \n",
    "            if significant:\n",
    "                if model1_better:\n",
    "                    print(f\"✅ {MODELS_TO_COMPARE[0]} significantly better than {MODELS_TO_COMPARE[1]}\")\n",
    "                else:\n",
    "                    print(f\"✅ {MODELS_TO_COMPARE[1]} significantly better than {MODELS_TO_COMPARE[0]}\")\n",
    "            else:\n",
    "                print(f\"❌ No significant difference between models\")\n",
    "            \n",
    "            # Create summary DataFrame\n",
    "            wilcoxon_summary = pd.DataFrame([result])\n",
    "            \n",
    "            print(\"\\n=== WILCOXON TEST SUMMARY ===\")\n",
    "            print(wilcoxon_summary[['Dataset', 'Mean1', 'Mean2', 'Mean_Diff', 'P_value_two', 'Significant', 'Model1_Better']].round(4))\n",
    "            \n",
    "            # Save results\n",
    "            wilcoxon_output_file = os.path.join(BASE_DIR, f\"wilcoxon_results_{MODELS_TO_COMPARE[0]}_vs_{MODELS_TO_COMPARE[1]}_{TARGET_DATASET}.xlsx\")\n",
    "            wilcoxon_summary.to_excel(wilcoxon_output_file, index=False)\n",
    "            print(f\"\\n✅ Wilcoxon results saved to: {wilcoxon_output_file}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in Wilcoxon test: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"❌ No paired data found for comparison\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No merged data available for Wilcoxon test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849f5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
