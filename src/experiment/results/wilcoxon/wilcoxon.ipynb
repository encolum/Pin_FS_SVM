{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c36d7e8",
   "metadata": {},
   "source": [
    "### Prepare the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe6ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bắt đầu merge cho dataset: cleveland ---\n",
      "\n",
      "Processing model: PinFSSVM\n",
      "  Loading: cleveland/original/PinFSSVM_auc_folds.xlsx\n",
      "  Loading: cleveland/noise/PinFSSVM_auc_folds.xlsx\n",
      "  Loading: cleveland/outlier/PinFSSVM_auc_folds.xlsx\n",
      "  Loading: cleveland/both/PinFSSVM_auc_folds.xlsx\n",
      "  Total samples for PinFSSVM: 40\n",
      "\n",
      "Processing model: MILP1\n",
      "  Loading: cleveland/original/MILP1_auc_folds.xlsx\n",
      "  Loading: cleveland/noise/MILP1_auc_folds.xlsx\n",
      "  Loading: cleveland/outlier/MILP1_auc_folds.xlsx\n",
      "  Loading: cleveland/both/MILP1_auc_folds.xlsx\n",
      "  Total samples for MILP1: 40\n",
      "\n",
      "Processing model: RFESVM\n",
      "  Loading: cleveland/original/RFESVM_auc_folds.xlsx\n",
      "  Loading: cleveland/noise/RFESVM_auc_folds.xlsx\n",
      "  Loading: cleveland/outlier/RFESVM_auc_folds.xlsx\n",
      "  Loading: cleveland/both/RFESVM_auc_folds.xlsx\n",
      "  Total samples for RFESVM: 40\n",
      "\n",
      "Processing model: FisherSVM\n",
      "  Loading: cleveland/original/FisherSVM_auc_folds.xlsx\n",
      "  Loading: cleveland/noise/FisherSVM_auc_folds.xlsx\n",
      "  Loading: cleveland/outlier/FisherSVM_auc_folds.xlsx\n",
      "  Loading: cleveland/both/FisherSVM_auc_folds.xlsx\n",
      "  Total samples for FisherSVM: 40\n",
      "\n",
      "Processing model: L1SVM\n",
      "  Loading: cleveland/original/L1SVM_auc_folds.xlsx\n",
      "  Loading: cleveland/noise/L1SVM_auc_folds.xlsx\n",
      "  Loading: cleveland/outlier/L1SVM_auc_folds.xlsx\n",
      "  Loading: cleveland/both/L1SVM_auc_folds.xlsx\n",
      "  Total samples for L1SVM: 40\n",
      "\n",
      "--- Kết quả merge cho dataset cleveland ---\n",
      "Total DataFrame shape: (200, 10)\n",
      "Total missing files: 0\n",
      "✅ Đã lưu dữ liệu merged vào: d:\\Optimal-Robust-Feature-Selection-For-Support-Vector-Machines-With-Pinball-Loss\\src\\experiment\\results\\wilcoxon\\cleveland\\merged_cleveland_data.xlsx\n",
      "   Shape: (200, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "current_dir = os.getcwd()\n",
    "# Đường dẫn gốc đến thư mục chứa dữ liệu wilcoxon\n",
    "BASE_DIR = current_dir\n",
    "\n",
    "# Danh sách các thành phần\n",
    "ALL_DATASETS = ['wdbc', 'sonar', 'ionosphere', 'diabetes', 'cleveland', 'colon']\n",
    "DATASET_TYPES = ['original', 'noise', 'outlier', 'both'] \n",
    "ALL_MODELS = ['RFESVM', 'PinFSSVM', 'PinballSVM', 'MILP1', 'L2SVM', 'L1SVM', 'FisherSVM']\n",
    "\n",
    "\n",
    "TARGET_DATASET = 'sonar' \n",
    "MODELS_TO_COMPARE = ['PinFSSVM', 'MILP1', 'RFESVM', 'FisherSVM', 'L1SVM']\n",
    "\n",
    "def load_excel_file(file_path):\n",
    "    \"\"\"Load dữ liệu từ file Excel và trả về DataFrame\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_excel(file_path)\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"  Warning: File not found: {file_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"  Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def merge_single_dataset(dataset_name, models_list):\n",
    "    \"\"\"Merge dữ liệu cho 1 dataset cụ thể và danh sách models\"\"\"\n",
    "    \n",
    "    all_data = []\n",
    "    missing_files = []\n",
    "    \n",
    "    print(f\"\\n--- Bắt đầu merge cho dataset: {dataset_name} ---\")\n",
    "    \n",
    "    for model in models_list:\n",
    "        print(f\"\\nProcessing model: {model}\")\n",
    "        model_data = []\n",
    "        \n",
    "        for dataset_type in DATASET_TYPES:\n",
    "            # Tạo đường dẫn đến file\n",
    "            file_path = os.path.join(BASE_DIR, dataset_name, dataset_type, f\"{model}_auc_folds.xlsx\")\n",
    "            \n",
    "            print(f\"  Loading: {dataset_name}/{dataset_type}/{model}_auc_folds.xlsx\")\n",
    "            \n",
    "            # Load dữ liệu\n",
    "            df = load_excel_file(file_path)\n",
    "            \n",
    "            if df is not None:\n",
    "                # Thêm thông tin metadata vào DataFrame\n",
    "                df['Model'] = model\n",
    "                df['Dataset'] = dataset_name\n",
    "                df['Dataset_Type'] = dataset_type\n",
    "                \n",
    "                # Thêm vào danh sách\n",
    "                model_data.append(df)\n",
    "                all_data.append(df)\n",
    "            else:\n",
    "                missing_files.append(file_path)\n",
    "        \n",
    "        # Tính số samples cho model này\n",
    "        total_samples_for_model = sum([len(df) for df in model_data])\n",
    "        print(f\"  Total samples for {model}: {total_samples_for_model}\")\n",
    "    \n",
    "    # Merge tất cả dữ liệu\n",
    "    if all_data:\n",
    "        merged_df = pd.concat(all_data, ignore_index=True)\n",
    "        print(f\"\\n--- Kết quả merge cho dataset {dataset_name} ---\")\n",
    "        print(f\"Total DataFrame shape: {merged_df.shape}\")\n",
    "        print(f\"Total missing files: {len(missing_files)}\")\n",
    "        \n",
    "        return merged_df, missing_files\n",
    "    else:\n",
    "        print(\"No data to merge!\")\n",
    "        return None, missing_files\n",
    "\n",
    "# Thực hiện merge cho dataset được chọn\n",
    "merged_data, missing_files = merge_single_dataset(TARGET_DATASET, MODELS_TO_COMPARE)\n",
    "\n",
    "\n",
    "# Lưu dữ liệu merged vào file Excel\n",
    "if merged_data is not None:\n",
    "    \n",
    "    # Tạo tên file output với tên dataset\n",
    "    output_file = os.path.join(BASE_DIR, TARGET_DATASET,f\"merged_{TARGET_DATASET}_data.xlsx\")\n",
    "    \n",
    "    try:\n",
    "        # Lưu vào Excel\n",
    "        merged_data.to_excel(output_file, index=False)\n",
    "        print(f\"✅ Đã lưu dữ liệu merged vào: {output_file}\")\n",
    "        print(f\"   Shape: {merged_data.shape}\")\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Lỗi khi lưu file: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Không có dữ liệu để lưu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a9cc042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha for testing: 0.05\n",
      "\n",
      "=== WILCOXON SIGNED-RANK TEST for dataset cleveland ===\n",
      "======================================================================\n",
      "\n",
      "PinFSSVM vs MILP1\n",
      "----------------------------------------\n",
      "Mean Difference: 0.0017\n",
      "95% CI: [-0.0055, 0.0090]\n",
      "P-value (two-sided): 0.7323\n",
      "P-value (PinFSSVM > MILP1): 0.3661\n",
      "Conclusion: No significant difference\n",
      "\n",
      "PinFSSVM vs RFESVM\n",
      "----------------------------------------\n",
      "Mean Difference: 0.0023\n",
      "95% CI: [-0.0068, 0.0115]\n",
      "P-value (two-sided): 0.6389\n",
      "P-value (PinFSSVM > RFESVM): 0.3194\n",
      "Conclusion: No significant difference\n",
      "\n",
      "PinFSSVM vs FisherSVM\n",
      "----------------------------------------\n",
      "Mean Difference: 0.0051\n",
      "95% CI: [-0.0059, 0.0160]\n",
      "P-value (two-sided): 0.4202\n",
      "P-value (PinFSSVM > FisherSVM): 0.2101\n",
      "Conclusion: No significant difference\n",
      "\n",
      "PinFSSVM vs L1SVM\n",
      "----------------------------------------\n",
      "Mean Difference: 0.0078\n",
      "95% CI: [-0.0012, 0.0168]\n",
      "P-value (two-sided): 0.0403\n",
      "P-value (PinFSSVM > L1SVM): 0.0201\n",
      "Conclusion: PinFSSVM significantly better\n",
      "\n",
      "✅ Results saved to: d:\\Optimal-Robust-Feature-Selection-For-Support-Vector-Machines-With-Pinball-Loss\\src\\experiment\\results\\wilcoxon\\cleveland\\wilcoxon_results_cleveland.xlsx\n",
      "Results shape: (4, 10)\n",
      "\n",
      "======================================================================\n",
      "\n",
      "=== SUMMARY RESULTS ===\n",
      "           Comparison   Dataset  Alpha  T_Critical  P_value_2sided  P_value_1sided  CI_Lower  CI_Upper  Mean_Difference                    Conclusion\n",
      "    PinFSSVM vs MILP1 cleveland   0.05    2.022691        0.732255        0.366127 -0.005540  0.008961         0.001710     No significant difference\n",
      "   PinFSSVM vs RFESVM cleveland   0.05    2.022691        0.638856        0.319428 -0.006783  0.011480         0.002348     No significant difference\n",
      "PinFSSVM vs FisherSVM cleveland   0.05    2.022691        0.420191        0.210096 -0.005884  0.016032         0.005074     No significant difference\n",
      "    PinFSSVM vs L1SVM cleveland   0.05    2.022691        0.040266        0.020133 -0.001172  0.016777         0.007802 PinFSSVM significantly better\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "import scipy.stats as stats\n",
    "alpha = 0.05\n",
    "print(f'Alpha for testing: {alpha}')\n",
    "\n",
    "def calculate_confidence_interval(data1, data2, confidence=0.95):\n",
    "    \"\"\"Calculate confidence interval for the difference between two samples\"\"\"\n",
    "    differences = data1 - data2\n",
    "    n = len(differences)\n",
    "    mean_diff = np.mean(differences)\n",
    "    std_diff = np.std(differences, ddof=1)\n",
    "    \n",
    "    # Calculate confidence interval\n",
    "    alpha = 1 - confidence\n",
    "    t_critical = stats.t.ppf(1 - alpha/2, n - 1)\n",
    "    margin_error = t_critical * (std_diff / np.sqrt(n))\n",
    "    \n",
    "    ci_lower = mean_diff - margin_error\n",
    "    ci_upper = mean_diff + margin_error\n",
    "    \n",
    "    return mean_diff, ci_lower, ci_upper, t_critical\n",
    "\n",
    "# Tạo danh sách để lưu kết quả\n",
    "results_log = []\n",
    "\n",
    "print(f\"\\n=== WILCOXON SIGNED-RANK TEST for dataset {TARGET_DATASET} ===\")\n",
    "print('='*70)\n",
    "\n",
    "for i in range(len(MODELS_TO_COMPARE)-1):\n",
    "    model1 = MODELS_TO_COMPARE[0]  \n",
    "    model2 = MODELS_TO_COMPARE[i+1]  \n",
    "    \n",
    "    # Take data for each model\n",
    "    model1_data = merged_data[merged_data['Model'] == model1].copy()\n",
    "    model2_data = merged_data[merged_data['Model'] == model2].copy()\n",
    "    \n",
    "    print(f\"\\n{model1} vs {model2}\")\n",
    "    print('-' * 40)\n",
    "    \n",
    "    # Make comparison DataFrame \n",
    "    comparison_df = pd.merge(\n",
    "        model1_data[['Dataset_Type', 'Fold', 'AUC']],\n",
    "        model2_data[['Dataset_Type', 'Fold', 'AUC']],\n",
    "        on=['Dataset_Type', 'Fold'],\n",
    "        suffixes=(f'_{model1}', f'_{model2}')\n",
    "    )\n",
    "    \n",
    "    if len(comparison_df) > 0:\n",
    "        auc1_col = f'AUC_{model1}'\n",
    "        auc2_col = f'AUC_{model2}'\n",
    "        \n",
    "        # Prepare for Wilcoxon test\n",
    "        model1_scores = comparison_df[auc1_col].values\n",
    "        model2_scores = comparison_df[auc2_col].values\n",
    "        \n",
    "        # Tính statistics và CI\n",
    "        mean_diff, ci_lower, ci_upper, t_critical = calculate_confidence_interval(model1_scores, model2_scores)\n",
    "        \n",
    "        # Wilcoxon test\n",
    "        statistic, p_value = wilcoxon(model1_scores, model2_scores, alternative='two-sided')\n",
    "        statistic_greater, p_value_greater = wilcoxon(model1_scores, model2_scores, alternative='greater')\n",
    "        \n",
    "        # Xác định kết luận dựa trên one-sided test\n",
    "        if p_value_greater < alpha:\n",
    "            conclusion = f\"{model1} significantly better\"\n",
    "        else:\n",
    "            # Kiểm tra hướng ngược lại\n",
    "            statistic_less, p_value_less = wilcoxon(model1_scores, model2_scores, alternative='less')\n",
    "            if p_value_less < alpha:\n",
    "                conclusion = f\"{model2} significantly better\"\n",
    "            else:\n",
    "                conclusion = \"No significant difference\"\n",
    "        \n",
    "        # Lưu vào log\n",
    "        result_row = {\n",
    "            'Comparison': f\"{model1} vs {model2}\",\n",
    "            'Dataset': TARGET_DATASET,\n",
    "            'Alpha': alpha,\n",
    "            'T_Critical': t_critical,\n",
    "            'P_value_2sided': p_value,\n",
    "            'P_value_1sided': p_value_greater,\n",
    "            'CI_Lower': ci_lower,\n",
    "            'CI_Upper': ci_upper,\n",
    "            'Mean_Difference': mean_diff,\n",
    "            'Conclusion': conclusion\n",
    "        }\n",
    "        results_log.append(result_row)\n",
    "        \n",
    "        # Compact output\n",
    "        print(f\"Mean Difference: {mean_diff:.4f}\")\n",
    "        print(f\"95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "        print(f\"P-value (two-sided): {p_value:.4f}\")\n",
    "        print(f\"P-value ({model1} > {model2}): {p_value_greater:.4f}\")\n",
    "        print(f\"Conclusion: {conclusion}\")\n",
    "        \n",
    "        # Save comparison results to Excel\n",
    "        comparison_df['Difference'] = comparison_df[auc1_col] - comparison_df[auc2_col]\n",
    "        comparison_output = os.path.join(BASE_DIR, TARGET_DATASET, f\"comparison_{model1}_vs_{model2}_{TARGET_DATASET}.xlsx\")\n",
    "        comparison_df.to_excel(comparison_output, index=False)\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ No matching data for comparison\")\n",
    "        # Thêm row với dữ liệu thiếu\n",
    "        result_row = {\n",
    "            'Comparison': f\"{model1} vs {model2}\",\n",
    "            'Dataset': TARGET_DATASET,\n",
    "            'Alpha': alpha,\n",
    "            'T_Critical': np.nan,\n",
    "            'P_value_2sided': np.nan,\n",
    "            'P_value_1sided': np.nan,\n",
    "            'CI_Lower': np.nan,\n",
    "            'CI_Upper': np.nan,\n",
    "            'Mean_Difference': np.nan,\n",
    "            'Conclusion': \"No matching data\"\n",
    "        }\n",
    "        results_log.append(result_row)\n",
    "\n",
    "# Tạo DataFrame từ kết quả và lưu vào Excel\n",
    "results_df = pd.DataFrame(results_log)\n",
    "results_output = os.path.join(BASE_DIR, TARGET_DATASET, f\"wilcoxon_results_{TARGET_DATASET}.xlsx\")\n",
    "results_df.to_excel(results_output, index=False)\n",
    "\n",
    "print(f\"\\n✅ Results saved to: {results_output}\")\n",
    "print(f\"Results shape: {results_df.shape}\")\n",
    "print('\\n' + '='*70)\n",
    "\n",
    "# Hiển thị bảng kết quả\n",
    "print(\"\\n=== SUMMARY RESULTS ===\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849f5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
