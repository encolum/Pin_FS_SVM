{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c2a18c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Wilcoxon Signed-Rank Test Script with Confidence Interval ---\n",
      "Dataset: diabetes - Type: both\n",
      "Comparing: PinFSSVM vs RFESVM\n",
      "Metric: AUC\n",
      "----------------------------------------\n",
      "Attempting to read: D:\\Pin_FS_SVM\\src\\experiment\\results\\wilcoxon\\diabetes\\both\\PinFSSVM_auc_folds.xlsx\n",
      "Attempting to read: D:\\Pin_FS_SVM\\src\\experiment\\results\\wilcoxon\\diabetes\\both\\RFESVM_auc_folds.xlsx\n",
      "----------------------------------------\n",
      "Performing Wilcoxon Signed-Rank Test (Two-Sided) with Confidence Interval\n",
      "Comparing: PinFSSVM vs RFESVM\n",
      "Alpha level: 0.05\n",
      "Scores for PinFSSVM (N=10): [0.63807692 0.68891403 0.59692982 0.78615385 0.70219298 0.66287879\n",
      " 0.67916667 0.67467949 0.68269231 0.72275641]\n",
      "Scores for RFESVM (N=10): [0.63807692 0.68891403 0.58815789 0.76615385 0.70219298 0.64772727\n",
      " 0.66354167 0.65384615 0.66185897 0.72275641]\n",
      "PinFSSVM Mean AUC: 0.6834\n",
      "RFESVM Mean AUC:    0.6733\n",
      "Differences (PinFSSVM - RFESVM): [0.         0.         0.00877193 0.02       0.         0.01515152\n",
      " 0.015625   0.02083333 0.02083333 0.        ]\n",
      "Median of Differences: 0.0120\n",
      "Wilcoxon Statistic: 0.0000\n",
      "P-value (two-sided): 0.0312\n",
      "95% CI for Median Difference (PinFSSVM - RFESVM): (0.0000, 0.0200)\n",
      "Conclusion: Statistically significant difference found (p < 0.05). PinFSSVM is likely better than RFESVM.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon, bootstrap # Thêm bootstrap\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- CẤU HÌNH CẦN THAY ĐỔI ---\n",
    "BASE_RESULTS_DIR = r'D:\\Pin_FS_SVM\\src\\experiment\\results'\n",
    "WILCOXON_DATA_SUBDIR = 'wilcoxon'\n",
    "METRIC_COLUMN_NAME = 'AUC'\n",
    "\n",
    "TARGET_DATASET_FOLDER = 'diabetes'  # Ví dụ: 'wdbc', 'colon', 'ionosphere'\n",
    "TARGET_DATASET_TYPE_FOLDER = 'both'\n",
    "MODEL1_CLASS_NAME = 'PinFSSVM'\n",
    "MODEL2_CLASS_NAME = 'RFESVM'\n",
    "\n",
    "ALPHA = 0.05 # Mức ý nghĩa\n",
    "N_BOOTSTRAP_RESAMPLES = 9999 # Số lần lặp bootstrap (nên > 1000)\n",
    "CONFIDENCE_LEVEL_FOR_CI = 0.95 # Mức tin cậy cho CI (tương ứng với alpha 0.05)\n",
    "# --- KẾT THÚC CẤU HÌNH ---\n",
    "\n",
    "def load_scores_from_file(dataset_folder, dataset_type_folder, model_name):\n",
    "    # ... (Hàm này giữ nguyên như trước) ...\n",
    "    file_path = os.path.join(BASE_RESULTS_DIR, WILCOXON_DATA_SUBDIR,\n",
    "                             dataset_folder, dataset_type_folder,\n",
    "                             f\"{model_name}_{METRIC_COLUMN_NAME.lower()}_folds.xlsx\")\n",
    "    print(f\"Attempting to read: {file_path}\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"  ERROR: File not found: {file_path}\")\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        if METRIC_COLUMN_NAME not in df.columns:\n",
    "            print(f\"  ERROR: Column '{METRIC_COLUMN_NAME}' not found in {file_path}\")\n",
    "            return None\n",
    "        scores = df[METRIC_COLUMN_NAME].values\n",
    "        if len(scores) == 0:\n",
    "            print(f\"  ERROR: No data in '{METRIC_COLUMN_NAME}' column in {file_path}\")\n",
    "            return None\n",
    "        if np.isnan(scores).any():\n",
    "            print(f\"  ERROR: NaN values found in '{METRIC_COLUMN_NAME}' column in {file_path}.\")\n",
    "            return None\n",
    "        return scores\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: Could not read file {file_path}. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_bootstrap_ci(data1, data2, n_resamples, confidence_level, statistic_func=np.median):\n",
    "    \"\"\"Tính CI cho một thống kê của sự khác biệt (data1 - data2) bằng bootstrap.\"\"\"\n",
    "    differences = np.array(data1) - np.array(data2)\n",
    "    if len(differences) < 5: # Bootstrap cần ít nhất 2 điểm, tốt hơn là nhiều hơn\n",
    "        print(\"  Warning: Not enough data points for bootstrap CI on differences.\")\n",
    "        return (np.nan, np.nan)\n",
    "    try:\n",
    "        res = bootstrap((differences,), statistic_func, confidence_level=confidence_level,\n",
    "                        n_resamples=n_resamples, method='percentile')\n",
    "        return (res.confidence_interval.low, res.confidence_interval.high)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during bootstrap CI calculation: {e}\")\n",
    "        return (np.nan, np.nan)\n",
    "\n",
    "def perform_single_wilcoxon_test_with_ci(scores1, scores2, model1_name, model2_name, alpha_level,\n",
    "                                         n_bootstrap_resamples, ci_confidence_level):\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Performing Wilcoxon Signed-Rank Test (Two-Sided) with Confidence Interval\")\n",
    "    # ... (phần print thông tin model, mean AUC, differences giữ nguyên như trước) ...\n",
    "    print(f\"Comparing: {model1_name} vs {model2_name}\")\n",
    "    print(f\"Alpha level: {alpha_level}\")\n",
    "    print(f\"Scores for {model1_name} (N={len(scores1)}): {scores1}\")\n",
    "    print(f\"Scores for {model2_name} (N={len(scores2)}): {scores2}\")\n",
    "    print(f\"{model1_name} Mean {METRIC_COLUMN_NAME}: {np.mean(scores1):.4f}\")\n",
    "    print(f\"{model2_name} Mean {METRIC_COLUMN_NAME}:    {np.mean(scores2):.4f}\")\n",
    "\n",
    "    if len(scores1) != len(scores2):\n",
    "        print(\"ERROR: Score lists have different lengths. Cannot perform paired test.\")\n",
    "        return\n",
    "    if len(scores1) < 5:\n",
    "        print(f\"WARNING: Sample size (N={len(scores1)}) is small. Test results might not be very reliable.\")\n",
    "\n",
    "    differences = scores1 - scores2\n",
    "    print(f\"Differences ({model1_name} - {model2_name}): {differences}\")\n",
    "    median_of_differences = np.median(differences)\n",
    "    print(f\"Median of Differences: {median_of_differences:.4f}\")\n",
    "\n",
    "\n",
    "    p_value = 1.0\n",
    "    statistic = np.nan\n",
    "    conclusion = \"Cannot conclude due to error or insufficient data.\"\n",
    "    ci_low, ci_high = (np.nan, np.nan)\n",
    "\n",
    "    if np.all(differences == 0):\n",
    "        print(\"All differences are zero. The two models performed identically on these folds.\")\n",
    "        p_value = 1.0\n",
    "        conclusion = \"No difference (p-value = 1.0).\"\n",
    "        ci_low, ci_high = (0.0, 0.0) \n",
    "    else:\n",
    "        try:\n",
    "            statistic, p_value = wilcoxon(scores1, scores2, alternative = 'two-sided')\n",
    "            print(f\"Wilcoxon Statistic: {statistic:.4f}\")\n",
    "            print(f\"P-value (two-sided): {p_value:.4f}\")\n",
    "\n",
    "            # Tính CI cho trung vị của sự khác biệt\n",
    "            ci_low, ci_high = get_bootstrap_ci(scores1, scores2, n_bootstrap_resamples, ci_confidence_level)\n",
    "            print(f\"{int(ci_confidence_level*100)}% CI for Median Difference ({model1_name} - {model2_name}): ({ci_low:.4f}, {ci_high:.4f})\")\n",
    "\n",
    "\n",
    "            if p_value < alpha_level:\n",
    "                conclusion = f\"Statistically significant difference found (p < {alpha_level}).\"\n",
    "                if ci_low >= 0 and ci_high >= 0 : # Khoảng CI hoàn toàn dương\n",
    "                    conclusion += f\" {model1_name} is likely better than {model2_name}.\"\n",
    "                elif ci_low < 0 and ci_high < 0: # Khoảng CI hoàn toàn âm\n",
    "                    conclusion += f\" {model2_name} is likely better than {model1_name}.\"\n",
    "            else:\n",
    "                conclusion = f\"No statistically significant difference found (p >= {alpha_level}).\"\n",
    "                if ci_low > 0 and ci_high > 0 : # Khoảng CI hoàn toàn dương\n",
    "                    conclusion += f\" Howerver, CI is positive means that {model1_name} is likely better than {model2_name}.\"\n",
    "                if ci_low <= 0 <= ci_high:\n",
    "                     conclusion += \" CI for median difference includes zero, supporting no significant difference.\"\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"ERROR during Wilcoxon test: {e}\")\n",
    "            conclusion = f\"Wilcoxon test could not be performed: {e}\"\n",
    "\n",
    "    print(f\"Conclusion: {conclusion}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Wilcoxon Signed-Rank Test Script with Confidence Interval ---\")\n",
    "    print(f\"Dataset: {TARGET_DATASET_FOLDER} - Type: {TARGET_DATASET_TYPE_FOLDER}\")\n",
    "    print(f\"Comparing: {MODEL1_CLASS_NAME} vs {MODEL2_CLASS_NAME}\")\n",
    "    print(f\"Metric: {METRIC_COLUMN_NAME}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    scores_m1 = load_scores_from_file(TARGET_DATASET_FOLDER, TARGET_DATASET_TYPE_FOLDER, MODEL1_CLASS_NAME)\n",
    "    scores_m2 = load_scores_from_file(TARGET_DATASET_FOLDER, TARGET_DATASET_TYPE_FOLDER, MODEL2_CLASS_NAME)\n",
    "\n",
    "    if scores_m1 is not None and scores_m2 is not None:\n",
    "        perform_single_wilcoxon_test_with_ci(scores_m1, scores_m2,\n",
    "                                             MODEL1_CLASS_NAME, MODEL2_CLASS_NAME,\n",
    "                                             ALPHA, N_BOOTSTRAP_RESAMPLES, CONFIDENCE_LEVEL_FOR_CI)\n",
    "    else:\n",
    "        print(\"\\nCould not perform test due to errors in loading data for one or both models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722aa1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b921f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
